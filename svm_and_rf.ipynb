{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Анастасия', (['прекрасный', 'воспоминание', 'вызывать', 'мультфильм', 'детство', 'обожать', 'знать', 'наизусть', 'весь', 'реплика', 'герой', 'песнь', 'прошлый', '10', 'год', 'вырасти', 'мультик', 'любить', 'по-прежнему', 'во-первых', 'отличный', 'яркий', 'картинка', 'нарисовать', 'превосходно', 'передраться', 'правда', 'красивый', 'пейзаж', 'красивый', 'платье', 'маленькая', 'девочка', 'просто', 'завораживать', 'двигаться', 'герой', 'очень', 'реалистично', 'хотя', 'это', 'проблема', 'американский', 'аниматор', 'во-вторых', 'озвучка', 'по-моему', 'наш', 'вариант', 'получиться', 'хороший', 'оригинал', 'огромный', 'спасибо', 'сказать', 'мария', 'кац', 'живой', 'исполнение', 'саундтрек', 'прекрасный', 'в-третьих', 'герой', 'маленький', 'девочка', 'верить', 'принц', 'просто', 'сразить', 'дмитрий', 'просто', 'воплощение', 'красота', 'постоянно', 'спасать', 'анастасий', 'глаз', 'становиться', 'весь', 'краш', 'упомянуть', 'барток', 'просто', 'разряжать', 'обстановка', 'некоторый', 'ситуация', 'единственный', 'пожалуй', 'последний', 'значимость', 'минус', 'это', 'фильм', 'нереалистичность', 'америка', 'история', 'россия', 'пожалуй', 'читать', 'сторона', 'забывать', 'это', 'мультфильм', 'ребёнок', 'снимать', 'сценарий', 'наш', 'история', 'получиться', 'мягко', 'говорить', 'жесткач', 'по-моему', 'мультик', 'очень', 'дотягивать', 'осмотреть', 'хотя', 'преступление', 'весь', 'советовать', '10', '10', 'ставить', 'полностью', 'заслуженно'], 'прекрасный воспоминание вызывать мультфильм детство обожать знать наизусть весь реплика герой песнь прошлый 10 год вырасти мультик любить по-прежнему во-первых отличный яркий картинка нарисовать превосходно передраться правда красивый пейзаж красивый платье маленькая девочка просто завораживать двигаться герой очень реалистично хотя это проблема американский аниматор во-вторых озвучка по-моему наш вариант получиться хороший оригинал огромный спасибо сказать мария кац живой исполнение саундтрек прекрасный в-третьих герой маленький девочка верить принц просто сразить дмитрий просто воплощение красота постоянно спасать анастасий глаз становиться весь краш упомянуть барток просто разряжать обстановка некоторый ситуация единственный пожалуй последний значимость минус это фильм нереалистичность америка история россия пожалуй читать сторона забывать это мультфильм ребёнок снимать сценарий наш история получиться мягко говорить жесткач по-моему мультик очень дотягивать осмотреть хотя преступление весь советовать 10 10 ставить полностью заслуженно'), '1')\n"
     ]
    }
   ],
   "source": [
    "# coding: utf8\n",
    "import math\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "import pandas\n",
    "import pymorphy2\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def normalize_review(review, morph):\n",
    "    \"\"\"\n",
    "\n",
    "    :param review:\n",
    "    :param morph:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = nltk.word_tokenize(review)\n",
    "    normalized_tokens = []\n",
    "    # normalized_review = ''\n",
    "    for token in tokens:\n",
    "        token = morph.parse(token)[0].normal_form\n",
    "        if token not in stop_words and token not in string.punctuation:\n",
    "            normalized_tokens.append(token.lower())\n",
    "\n",
    "    return normalized_tokens, \" \".join(normalized_tokens)\n",
    "\n",
    "\n",
    "def get_my_reviews(morph):\n",
    "    \"\"\"\n",
    "    Получаем мои ревью из эксель таблицы.\n",
    "\n",
    "    :param morph:\n",
    "    :return tuple: (название фильма, текст ревью, реальный класс ревью)\n",
    "    \"\"\"\n",
    "    pos_reviews = []\n",
    "    neg_reviews = []\n",
    "    neutr_reviews = []\n",
    "    \n",
    "    excel_file = pandas.read_excel('Отзывы кино.xlsx', 0)\n",
    "    for i, row in excel_file.iterrows():\n",
    "        if (row['title'] == 'Криминальное чтиво' or\n",
    "                row['title'] == 'Маленькая Мисс Счастье' or\n",
    "                row['title'] == 'Амели'):\n",
    "            \n",
    "            if row['label'] == 1:\n",
    "                pos_reviews.append((row['title'], normalize_review(row['text'], morph),\n",
    "                            str(row['label'])))\n",
    "            if row['label'] == -1:\n",
    "                neg_reviews.append((row['title'], normalize_review(row['text'], morph),\n",
    "                            str(row['label'])))\n",
    "            if row['label'] == 0:\n",
    "                neutr_reviews.append((row['title'], normalize_review(row['text'], morph),\n",
    "                            str(row['label'])))\n",
    "\n",
    "    return pos_reviews, neg_reviews, neutr_reviews\n",
    "\n",
    "\n",
    "def get_reviews(morph):\n",
    "    \"\"\"\n",
    "    Получаем ревью одногруппников из эксель таблицы.\n",
    "\n",
    "    :param morph:\n",
    "    :return tuple: (название фильма, список токенов, реальный класс ревью)\n",
    "    \"\"\"\n",
    "    pos_reviews = []\n",
    "    neg_reviews = []\n",
    "    neutr_reviews = []\n",
    "    \n",
    "    excel_file = pandas.read_excel('Отзывы кино.xlsx', 0)\n",
    "    for i, row in excel_file.iterrows():\n",
    "        if (row['title'] != 'Криминальное чтиво' and\n",
    "                row['title'] != 'Маленькая Мисс Счастье' and\n",
    "                row['title'] != 'Амели'):\n",
    "            if row['label'] == 1:\n",
    "                pos_reviews.append((row['title'], normalize_review(row['text'], morph),\n",
    "                            str(row['label'])))\n",
    "            if row['label'] == -1:\n",
    "                neg_reviews.append((row['title'], normalize_review(row['text'], morph),\n",
    "                            str(row['label'])))\n",
    "            if row['label'] == 0:\n",
    "                neutr_reviews.append((row['title'], normalize_review(row['text'], morph),\n",
    "                            str(row['label'])))\n",
    "            \n",
    "\n",
    "    return pos_reviews, neg_reviews, neutr_reviews\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "stop_words = stopwords.words('russian')\n",
    "stop_words.extend(['«', '»', '–', '...', '“', '”', '—', '!',\n",
    "                   '@', '№', ':', ',', '.', '?', ':', '(', ')'])\n",
    "stop_words = set(stop_words)\n",
    "\n",
    "train_positive_reviews, train_negative_reviews, train_neutral_reviews = get_reviews(morph)\n",
    "test_positive_reviews, test_negative_reviews, test_neutral_reviews = get_my_reviews(morph)\n",
    "\n",
    "print(train_positive_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анастасия\n",
      "(['прекрасный', 'воспоминание', 'вызывать', 'мультфильм', 'детство', 'обожать', 'знать', 'наизусть', 'весь', 'реплика', 'герой', 'песнь', 'прошлый', '10', 'год', 'вырасти', 'мультик', 'любить', 'по-прежнему', 'во-первых', 'отличный', 'яркий', 'картинка', 'нарисовать', 'превосходно', 'передраться', 'правда', 'красивый', 'пейзаж', 'красивый', 'платье', 'маленькая', 'девочка', 'просто', 'завораживать', 'двигаться', 'герой', 'очень', 'реалистично', 'хотя', 'это', 'проблема', 'американский', 'аниматор', 'во-вторых', 'озвучка', 'по-моему', 'наш', 'вариант', 'получиться', 'хороший', 'оригинал', 'огромный', 'спасибо', 'сказать', 'мария', 'кац', 'живой', 'исполнение', 'саундтрек', 'прекрасный', 'в-третьих', 'герой', 'маленький', 'девочка', 'верить', 'принц', 'просто', 'сразить', 'дмитрий', 'просто', 'воплощение', 'красота', 'постоянно', 'спасать', 'анастасий', 'глаз', 'становиться', 'весь', 'краш', 'упомянуть', 'барток', 'просто', 'разряжать', 'обстановка', 'некоторый', 'ситуация', 'единственный', 'пожалуй', 'последний', 'значимость', 'минус', 'это', 'фильм', 'нереалистичность', 'америка', 'история', 'россия', 'пожалуй', 'читать', 'сторона', 'забывать', 'это', 'мультфильм', 'ребёнок', 'снимать', 'сценарий', 'наш', 'история', 'получиться', 'мягко', 'говорить', 'жесткач', 'по-моему', 'мультик', 'очень', 'дотягивать', 'осмотреть', 'хотя', 'преступление', 'весь', 'советовать', '10', '10', 'ставить', 'полностью', 'заслуженно'], 'прекрасный воспоминание вызывать мультфильм детство обожать знать наизусть весь реплика герой песнь прошлый 10 год вырасти мультик любить по-прежнему во-первых отличный яркий картинка нарисовать превосходно передраться правда красивый пейзаж красивый платье маленькая девочка просто завораживать двигаться герой очень реалистично хотя это проблема американский аниматор во-вторых озвучка по-моему наш вариант получиться хороший оригинал огромный спасибо сказать мария кац живой исполнение саундтрек прекрасный в-третьих герой маленький девочка верить принц просто сразить дмитрий просто воплощение красота постоянно спасать анастасий глаз становиться весь краш упомянуть барток просто разряжать обстановка некоторый ситуация единственный пожалуй последний значимость минус это фильм нереалистичность америка история россия пожалуй читать сторона забывать это мультфильм ребёнок снимать сценарий наш история получиться мягко говорить жесткач по-моему мультик очень дотягивать осмотреть хотя преступление весь советовать 10 10 ставить полностью заслуженно')\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train_positive_reviews[0][0])\n",
    "print(train_positive_reviews[0][1])\n",
    "print(train_positive_reviews[0][2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_pos_reviews = [item[1][1] for item in train_positive_reviews]\n",
    "train_neg_reviews = [item[1][1] for item in train_negative_reviews]\n",
    "train_neutr_reviews = [item[1][1] for item in train_neutral_reviews]\n",
    "\n",
    "test_pos_reviews = [item[1][1] for item in test_positive_reviews]\n",
    "test_neg_reviews = [item[1][1] for item in test_negative_reviews]\n",
    "test_neutr_reviews = [item[1][1] for item in test_neutral_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X = train_pos_reviews + train_neg_reviews + train_neutr_reviews\n",
    "Train_Y = [1]*len(train_pos_reviews) + [-1]*len(train_neg_reviews) + [0]*len(train_neutr_reviews)\n",
    "\n",
    "Test_X = test_pos_reviews + test_neg_reviews + test_neutr_reviews\n",
    "Test_Y = [1]*len(test_pos_reviews) + [-1]*len(test_neg_reviews) + [0]*len(test_neutr_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Encoder = LabelEncoder()\n",
    "# Train_Y = Encoder.fit_transform(Train_Y)\n",
    "print(Train_Y)\n",
    "# Test_Y = Encoder.fit_transform(Test_Y)\n",
    "print(Test_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X = vectorizer.fit_transform(Train_X).toarray()\n",
    "Test_X = vectorizer.transform(Test_X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC(max_iter=10000)\n",
    "clf.fit(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1 -1  1 -1  1  1 -1  0  1 -1 -1  0  1  1  1  1  0  1  1  0  0\n",
      "  1 -1  1  1  1  1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1\n",
      " -1  0 -1  0  1 -1  0 -1  0 -1  0  0 -1  1 -1 -1  0  1 -1  1 -1  1 -1  1\n",
      " -1  1  1  0  1  0 -1 -1  0 -1  1  1  1  1  1  0  1  0]\n",
      "SVM Accuracy Score ->  51.11111111111111\n"
     ]
    }
   ],
   "source": [
    "# predict the labels on validation dataset\n",
    "predictions_SVM = clf.predict(Test_X)\n",
    "print(predictions_SVM)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[ 1  1  1  1 -1  1 -1  1  1 -1  0  1 -1 -1  0  1  1  1  1  0  1  1  0  0\n",
      "  1 -1  1  1  1  1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1\n",
      " -1  0 -1  0  1 -1  0 -1  0 -1  0  0 -1  1 -1 -1  0  1 -1  1 -1  1 -1  1\n",
      " -1  1  1  0  1  0 -1 -1  0 -1  1  1  1  1  1  0  1  0]\n",
      "(0.4827621739386445, 0.5111111111111111, 0.4859807987785123, None)\n",
      "(0.5111111111111111, 0.5111111111111111, 0.5111111111111111, None)\n",
      "(0.4827621739386445, 0.5111111111111111, 0.4859807987785123, None)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "y_true = Test_Y\n",
    "print(y_true)\n",
    "y_pred = predictions_SVM\n",
    "print(y_pred)\n",
    "\n",
    "print(precision_recall_fscore_support(y_true, y_pred, average='macro'))\n",
    "\n",
    "print(precision_recall_fscore_support(y_true, y_pred, average='micro'))\n",
    "\n",
    "print(precision_recall_fscore_support(y_true, y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.56756757, 0.35294118, 0.52777778]),\n",
       " array([0.7       , 0.2       , 0.63333333]),\n",
       " array([0.62686567, 0.25531915, 0.57575758]),\n",
       " array([30, 30, 30], dtype=int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_true, y_pred, average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=20, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclf = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "rfclf.fit(Train_X, Train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1  1  1  1  1  1 -1  1  0  0  0  0 -1  1  1  1  1  1  0  0\n",
      "  1  0  1  1  1  1  0  0  1 -1 -1  0 -1 -1 -1 -1  1 -1 -1  0  1  0  0  0\n",
      " -1  0  0  0  1 -1 -1 -1 -1 -1  1  0  1  1  1  1  1  0  1  0 -1  0  1  1\n",
      " -1  1  1  0  0  0 -1  1  1  1  1  1  0  1  0  0  1  0]\n",
      "RF Accuracy Score ->  50.0\n"
     ]
    }
   ],
   "source": [
    "# predict the labels on validation dataset\n",
    "predictions_RF = rfclf.predict(Test_X)\n",
    "print(predictions_RF)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"RF Accuracy Score -> \",accuracy_score(predictions_RF, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5274523518097569, 0.5, 0.49719954112963083, None)\n"
     ]
    }
   ],
   "source": [
    "print(precision_recall_fscore_support(Test_Y, predictions_RF, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'прекрасный воспоминание вызывать мультфильм детство обожать знать наизусть весь реплика герой песнь прошлый 10 год вырасти мультик любить по-прежнему во-первых отличный яркий картинка нарисовать превосходно передраться правда красивый пейзаж красивый платье маленькая девочка просто завораживать двигаться герой очень реалистично хотя это проблема американский аниматор во-вторых озвучка по-моему наш вариант получиться хороший оригинал огромный спасибо сказать мария кац живой исполнение саундтрек прекрасный в-третьих герой маленький девочка верить принц просто сразить дмитрий просто воплощение красота постоянно спасать анастасий глаз становиться весь краш упомянуть барток просто разряжать обстановка некоторый ситуация единственный пожалуй последний значимость минус это фильм нереалистичность америка история россия пожалуй читать сторона забывать это мультфильм ребёнок снимать сценарий наш история получиться мягко говорить жесткач по-моему мультик очень дотягивать осмотреть хотя преступление весь советовать 10 10 ставить полностью заслуженно', 'nouns_cnt': 50, 'verbs_cnt': 26, 'adjective_cnt': 22, 'adverb_cnt': 14, 'punct_chars_cnt': 6}\n"
     ]
    }
   ],
   "source": [
    "# Добавляем части речи и пунктуацию в вектор\n",
    "\n",
    "import nltk\n",
    "import pandas\n",
    "import pymorphy2\n",
    "import sklearn\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def normalize_review(review, morph):\n",
    "    \"\"\"\n",
    "\n",
    "    :param review:\n",
    "    :param morph:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    punct_chars = []\n",
    "    nouns = 0\n",
    "    verbs = 0\n",
    "    adverbs = 0\n",
    "    adjs = 0\n",
    "    tokens = nltk.word_tokenize(review)\n",
    "    normalized_tokens = []\n",
    "    # normalized_review = ''\n",
    "    for token in tokens:\n",
    "        token =  morph.parse(token)[0]\n",
    "        if token.tag.POS == 'ADJF':\n",
    "            adjs += 1\n",
    "        elif token.tag.POS == 'NOUN':\n",
    "            nouns += 1\n",
    "        elif token.tag.POS == 'INFN' or token.tag.POS == 'VERB':\n",
    "            verbs += 1\n",
    "        elif token.tag.POS == 'ADVB':\n",
    "            adverbs += 1\n",
    "        token = token.normal_form\n",
    "        if token not in stop_words and token not in string.punctuation:\n",
    "            normalized_tokens.append(token.lower())\n",
    "        if token in string.punctuation and token not in punct_chars:\n",
    "            punct_chars.append(token)\n",
    "            \n",
    "\n",
    "    return normalized_tokens, \" \".join(normalized_tokens), len(punct_chars), nouns, verbs, adverbs, adjs\n",
    "\n",
    "\n",
    "def get_my_reviews(morph):\n",
    "    \"\"\"\n",
    "    Получаем мои ревью из эксель таблицы.\n",
    "\n",
    "    :param morph:\n",
    "    :return tuple: (название фильма, текст ревью, реальный класс ревью)\n",
    "    \"\"\"\n",
    "    pos_reviews = []\n",
    "    neg_reviews = []\n",
    "    neutr_reviews = []\n",
    "    \n",
    "    excel_file = pandas.read_excel('Отзывы кино.xlsx', 0)\n",
    "    for i, row in excel_file.iterrows():\n",
    "        if (row['title'] == 'Криминальное чтиво' or\n",
    "                row['title'] == 'Маленькая Мисс Счастье' or\n",
    "                row['title'] == 'Амели'):\n",
    "            \n",
    "            preprocessed = normalize_review(row['text'], morph)\n",
    "            \n",
    "            d = {\n",
    "                'text': preprocessed[1],\n",
    "                'nouns_cnt': preprocessed[3],\n",
    "                'verbs_cnt': preprocessed[4],\n",
    "                'adjective_cnt': preprocessed[6],\n",
    "                'adverb_cnt': preprocessed[5],\n",
    "                'punct_chars_cnt': preprocessed[2]\n",
    "            }\n",
    "            \n",
    "            if row['label'] == 1:\n",
    "                pos_reviews.append(d)\n",
    "            if row['label'] == -1:\n",
    "                neg_reviews.append(d)\n",
    "            if row['label'] == 0:\n",
    "                neutr_reviews.append(d)\n",
    "\n",
    "    return pos_reviews, neg_reviews, neutr_reviews\n",
    "\n",
    "\n",
    "def get_reviews(morph):\n",
    "    \"\"\"\n",
    "    Получаем ревью одногруппников из эксель таблицы.\n",
    "\n",
    "    :param morph:\n",
    "    :return tuple: (название фильма, список токенов, реальный класс ревью)\n",
    "    \"\"\"\n",
    "    pos_reviews = []\n",
    "    neg_reviews = []\n",
    "    neutr_reviews = []\n",
    "    \n",
    "    excel_file = pandas.read_excel('Отзывы кино.xlsx', 0)\n",
    "    for i, row in excel_file.iterrows():\n",
    "        if (row['title'] != 'Криминальное чтиво' and\n",
    "                row['title'] != 'Маленькая Мисс Счастье' and\n",
    "                row['title'] != 'Амели'):\n",
    "            \n",
    "            preprocessed = normalize_review(row['text'], morph)\n",
    "            \n",
    "            d = {\n",
    "                'text': preprocessed[1],\n",
    "                'nouns_cnt': preprocessed[3],\n",
    "                'verbs_cnt': preprocessed[4],\n",
    "                'adjective_cnt': preprocessed[6],\n",
    "                'adverb_cnt': preprocessed[5],\n",
    "                'punct_chars_cnt': preprocessed[2]\n",
    "            }\n",
    "            \n",
    "            if row['label'] == 1:\n",
    "                pos_reviews.append(d)\n",
    "            if row['label'] == -1:\n",
    "                neg_reviews.append(d)\n",
    "            if row['label'] == 0:\n",
    "                neutr_reviews.append(d)\n",
    "            \n",
    "\n",
    "    return pos_reviews, neg_reviews, neutr_reviews\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "stop_words = ['«', '»', '...', '“', '”', '—', '№']\n",
    "stop_words.extend(stopwords.words('russian'))\n",
    "stop_words = set(stop_words)\n",
    "\n",
    "train_positive_reviews, train_negative_reviews, train_neutral_reviews = get_reviews(morph)\n",
    "test_positive_reviews, test_negative_reviews, test_neutral_reviews = get_my_reviews(morph)\n",
    "\n",
    "print(train_positive_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X = train_positive_reviews + train_negative_reviews + train_neutral_reviews\n",
    "Train_Y = [1]*len(train_positive_reviews) + [-1]*len(train_negative_reviews) + [0]*len(train_neutral_reviews)\n",
    "\n",
    "Test_X = test_positive_reviews + test_negative_reviews + test_neutral_reviews\n",
    "Test_Y = [1]*len(test_positive_reviews) + [-1]*len(test_negative_reviews) + [0]*len(test_neutral_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'сочинение тема любить криминальный чтиво начало хотеть сказать просто обажай фильм пересматривать 30 маленький знать наизусть практически каждый диалог постоянно цитировать полюбиться фраза также считать картина хороший творчество замечательный режиссёр квентин тарантино хороший весь история кино написать это сочинение сподвигнуть искренний недоумение некоторый индивид – почему весь любить превозносить криминальный чтиво весь ответить смочь попробовать итак любить криминальный чтиво во-первых сценарий великолепный скрипт написать тарантино совместно роджер эверь сильно выделяться фон остальной свой оригинальность остроумие известно эверь полностью написать новелла золотой часы весь остальной являться результат творчество квентин хороший сценарий весь замечательный диалог давно стать культовый – думать разговор винсент джулс массаж нога жизнь европа знать практически каждый киноман превосходный персонаж – отморозок цитировать библия боксёр-неудачник готовый умереть отцовский часы неудавшийся актриса-наркоманка стать жена мафиозить неожиданный остроумный поворот сюжет – божественный вмешательство встреча боксёр мафиозить выстрел машина т.д стать знаменитый игра хронология – новелла идти порядок перепутать время гениальный сценарий во-вторых актёр тарантино вновь бешеный пёс удаться собрать свой фильм просто замечательный актёр это маленький бюджет джон траволта роль винсент чрезвычайно хороший – эдакий безбашенный отморозок способный убить любой сыграть роль отлично сэмюэль джексон роль джулс менее хороший гангстер цитировать библия – это офигенный стёб брюс уиллис исполнить роль бутч взгляд сыграть худой предыдущий актёр весь равно всё-таки роль слишком умный боксёр-неудачник распологать какой-то феноменальный игра мия уоллес исполнение ум турман сыграть честно говорить понравиться выглядеть внешне убить билл порядок симпатичный стоить забывать второстепенный роль исполнение винга реймс харви кейтеля тим рота – классно отыграть свой персонаж в-третьих режиссура превосходный режиссура тарантино просто рвать башня выстривать кадр работать актёр это учиться киношкола атмосфера съёмка фильм наверняка замечательный создание хороша атмосфера съёмочный коллектив являться главный задача режиссёр многие сказать тарантино известный плагиатор воровать какой-то находка фильм возможно это это прелесть картина это называть радость киноман находить фильм какой-нибудь отсылка картина начинать испытывать искренний радость тип ага картина стена точно висеть друг фильм отсылка фильм квентин огромный множество заядлый киноман долгий время проработать кинопрокат сценарий актёр режиссура – это весь достоинство фильм ещё великолепный музыка монтаж операторский работа т.д охватить весь это нужно писать целовать книга сожаление ограниченный объём текст поэтому выделить самый главное достоинство криминальный чтиво культовый фильм получить множество приз обрести толпа поклонник породить огромный количество клон подражатель великое кино', 'nouns_cnt': 175, 'verbs_cnt': 53, 'adjective_cnt': 80, 'adverb_cnt': 26, 'punct_chars_cnt': 7}\n"
     ]
    }
   ],
   "source": [
    "print(test_positive_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'прекрасный воспоминание вызывать мультфильм детство обожать знать наизусть весь реплика герой песнь прошлый 10 год вырасти мультик любить по-прежнему во-первых отличный яркий картинка нарисовать превосходно передраться правда красивый пейзаж красивый платье маленькая девочка просто завораживать двигаться герой очень реалистично хотя это проблема американский аниматор во-вторых озвучка по-моему наш вариант получиться хороший оригинал огромный спасибо сказать мария кац живой исполнение саундтрек прекрасный в-третьих герой маленький девочка верить принц просто сразить дмитрий просто воплощение красота постоянно спасать анастасий глаз становиться весь краш упомянуть барток просто разряжать обстановка некоторый ситуация единственный пожалуй последний значимость минус это фильм нереалистичность америка история россия пожалуй читать сторона забывать это мультфильм ребёнок снимать сценарий наш история получиться мягко говорить жесткач по-моему мультик очень дотягивать осмотреть хотя преступление весь советовать 10 10 ставить полностью заслуженно',\n",
       " 'nouns_cnt': 50,\n",
       " 'verbs_cnt': 26,\n",
       " 'adjective_cnt': 22,\n",
       " 'adverb_cnt': 14,\n",
       " 'punct_chars_cnt': 6}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>nouns_cnt</th>\n",
       "      <th>verbs_cnt</th>\n",
       "      <th>adjective_cnt</th>\n",
       "      <th>adverb_cnt</th>\n",
       "      <th>punct_chars_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>прекрасный воспоминание вызывать мультфильм де...</td>\n",
       "      <td>50</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>хотя мультфильм создать 1997 совершенно мочь п...</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>любимый мультфильм детство любим поныне должны...</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>время свержение монархия революция расстрел ца...</td>\n",
       "      <td>93</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>великий княжна анастасий дочь последний русски...</td>\n",
       "      <td>149</td>\n",
       "      <td>51</td>\n",
       "      <td>84</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605</td>\n",
       "      <td>нейтральный рецензия 'то понравиться свой дово...</td>\n",
       "      <td>113</td>\n",
       "      <td>53</td>\n",
       "      <td>90</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>606</td>\n",
       "      <td>из-за незабитый гвоздь потерять подкова из-за ...</td>\n",
       "      <td>123</td>\n",
       "      <td>51</td>\n",
       "      <td>75</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>607</td>\n",
       "      <td>выход самый удачный серия быстрый неистовый пр...</td>\n",
       "      <td>87</td>\n",
       "      <td>47</td>\n",
       "      <td>60</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>608</td>\n",
       "      <td>правильно говорят каждый цепь насколько крепки...</td>\n",
       "      <td>172</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609</td>\n",
       "      <td>тройной форсажа токийский дрифт это продолжени...</td>\n",
       "      <td>181</td>\n",
       "      <td>54</td>\n",
       "      <td>111</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  nouns_cnt  verbs_cnt  \\\n",
       "0    прекрасный воспоминание вызывать мультфильм де...         50         26   \n",
       "1    хотя мультфильм создать 1997 совершенно мочь п...         34         24   \n",
       "2    любимый мультфильм детство любим поныне должны...         24         10   \n",
       "3    время свержение монархия революция расстрел ца...         93         44   \n",
       "4    великий княжна анастасий дочь последний русски...        149         51   \n",
       "..                                                 ...        ...        ...   \n",
       "605  нейтральный рецензия 'то понравиться свой дово...        113         53   \n",
       "606  из-за незабитый гвоздь потерять подкова из-за ...        123         51   \n",
       "607  выход самый удачный серия быстрый неистовый пр...         87         47   \n",
       "608  правильно говорят каждый цепь насколько крепки...        172         80   \n",
       "609  тройной форсажа токийский дрифт это продолжени...        181         54   \n",
       "\n",
       "     adjective_cnt  adverb_cnt  punct_chars_cnt  \n",
       "0               22          14                6  \n",
       "1               23          11                6  \n",
       "2               15          10                2  \n",
       "3               48          19                3  \n",
       "4               84          28                4  \n",
       "..             ...         ...              ...  \n",
       "605             90          34                7  \n",
       "606             75          28                4  \n",
       "607             60          48                4  \n",
       "608             88          50                9  \n",
       "609            111          36                6  \n",
       "\n",
       "[610 rows x 6 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(Train_X)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "mapper = DataFrameMapper(\n",
    "    [\n",
    "        ('text', CountVectorizer()),\n",
    "        (['nouns_cnt', 'verbs_cnt', 'adjective_cnt', 'adverb_cnt', 'punct_chars_cnt'], None)\n",
    "    ])\n",
    "X = mapper.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  22,  14,   6],\n",
       "       [  0,   0,   0, ...,  23,  11,   6],\n",
       "       [  0,   0,   0, ...,  15,  10,   2],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  60,  48,   4],\n",
       "       [  0,   0,   0, ...,  88,  50,   9],\n",
       "       [  0,   0,   0, ..., 111,  36,   6]], dtype=int64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=20, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclf = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "rfclf.fit(X, Train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  80,  26,   7],\n",
       "       [  0,   0,   0, ..., 139,  36,   7],\n",
       "       [  0,   0,   0, ..., 138,  38,  10],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   8,   2,   5],\n",
       "       [  0,   0,   0, ...,  28,  11,   8],\n",
       "       [  0,   0,   0, ...,  43,  17,   8]], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(Test_X)\n",
    "\n",
    "X_test = mapper.transform(df_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1  1  1  1  1  1 -1  1 -1 -1  0  0  1  1  1  1  0  1  0  0\n",
      "  1  1  1  1  1  1 -1 -1  1 -1  1 -1 -1 -1 -1 -1  1 -1 -1  0  0 -1  0 -1\n",
      " -1 -1  1 -1  1 -1 -1 -1  1 -1 -1  0  1  1  1  1  1  0  1  1  0 -1  1  1\n",
      "  1  1  0  0  1  1 -1  1  0  1  1  1  0  1  1  0  1  0]\n",
      "RF Accuracy Score ->  55.55555555555556\n"
     ]
    }
   ],
   "source": [
    "# predict the labels on validation dataset\n",
    "predictions_RF = rfclf.predict(X_test)\n",
    "print(predictions_RF)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"RF Accuracy Score -> \",accuracy_score(predictions_RF, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5763071895424836, 0.5555555555555556, 0.543933607763395, None)\n"
     ]
    }
   ],
   "source": [
    "print(precision_recall_fscore_support(Test_Y, predictions_RF, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1  1  0  1 -1  0  0  0  1  1  1  1 -1  0  1  1  1  0 -1 -1  0  0\n",
      "  1 -1  0  0  0  1 -1 -1  1  1  0 -1 -1  0  1  1 -1  0 -1  1 -1  1  0  0\n",
      "  0  0 -1  0  1 -1  1 -1  1 -1  1  1 -1  0 -1  1  1  1 -1  0 -1  0  1  1\n",
      "  0  0  0 -1 -1 -1  1  1  1 -1  0  1  0 -1 -1  0  1  0]\n",
      "RF Accuracy Score ->  37.77777777777778\n",
      "(0.37819597826359147, 0.37777777777777777, 0.37706598770938643, None)\n"
     ]
    }
   ],
   "source": [
    "# Без мешка слов\n",
    "\n",
    "\n",
    "df = pd.DataFrame(Train_X)\n",
    "X_train_without_bow_df = df.drop(['text'], axis=1)\n",
    "\n",
    "df_test = pd.DataFrame(Test_X)\n",
    "X_test_without_bow_df = df_test.drop(['text'], axis=1)\n",
    "\n",
    "mapper = DataFrameMapper(\n",
    "    [\n",
    "#         ('text', CountVectorizer()),\n",
    "        (['nouns_cnt', 'verbs_cnt', 'adjective_cnt', 'adverb_cnt', 'punct_chars_cnt'], None)\n",
    "    ])\n",
    "\n",
    "X = mapper.fit_transform(X_train_without_bow_df)\n",
    "X_test = mapper.transform(X_test_without_bow_df)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclf = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "rfclf.fit(X, Train_Y)\n",
    "\n",
    "predictions_RF = rfclf.predict(X_test)\n",
    "print(predictions_RF)\n",
    "print(\"RF Accuracy Score -> \",accuracy_score(predictions_RF, Test_Y)*100)\n",
    "print(precision_recall_fscore_support(Test_Y, predictions_RF, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1  1  1  1  1  1  0  1 -1 -1  0  0  1  1  1  1  1  1  1  0\n",
      "  1  1  1  1  1  1 -1 -1  1 -1 -1 -1 -1 -1 -1  0 -1  1 -1  0 -1 -1  0 -1\n",
      "  0 -1  0 -1  1 -1 -1 -1 -1 -1  1  0  1  1  1  1  1  0 -1  0 -1 -1  1  1\n",
      "  0  1  0  0 -1  0 -1 -1  1  1  1  1  0  1  1  0  1  0]\n",
      "RF Accuracy Score ->  58.88888888888889\n",
      "(0.5820364865652503, 0.5888888888888889, 0.5715121192548819, None)\n"
     ]
    }
   ],
   "source": [
    "# Без частей речи\n",
    "\n",
    "\n",
    "df = pd.DataFrame(Train_X)\n",
    "X_train_without_pos_df = df.drop(['nouns_cnt', 'verbs_cnt', 'adjective_cnt', 'adverb_cnt'], axis=1)\n",
    "\n",
    "df_test = pd.DataFrame(Test_X)\n",
    "X_test_without_pos_df = df_test.drop(['nouns_cnt', 'verbs_cnt', 'adjective_cnt', 'adverb_cnt'], axis=1)\n",
    "\n",
    "mapper = DataFrameMapper(\n",
    "    [\n",
    "        ('text', CountVectorizer()),\n",
    "        (['punct_chars_cnt'], None)\n",
    "    ])\n",
    "\n",
    "X = mapper.fit_transform(X_train_without_pos_df)\n",
    "X_test = mapper.transform(X_test_without_pos_df)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclf = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "rfclf.fit(X, Train_Y)\n",
    "\n",
    "predictions_RF = rfclf.predict(X_test)\n",
    "print(predictions_RF)\n",
    "print(\"RF Accuracy Score -> \",accuracy_score(predictions_RF, Test_Y)*100)\n",
    "print(precision_recall_fscore_support(Test_Y, predictions_RF, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1  1  1  1  1  1  1  1 -1 -1  0  0  1  1  1  1  1  1  0  0\n",
      "  1  1  1  1  1  1  0 -1  1 -1  1 -1 -1 -1 -1  0  1  0  1 -1  1 -1  0  0\n",
      " -1 -1  0 -1  1 -1 -1 -1 -1 -1 -1  1  1  1  0  1  1  0  1  0 -1  0  1  1\n",
      "  1  1  0  0 -1 -1 -1 -1  1  1  1  1  0  1  0  0  1  0]\n",
      "RF Accuracy Score ->  56.666666666666664\n",
      "(0.5766908212560387, 0.5666666666666667, 0.5537361923326836, None)\n"
     ]
    }
   ],
   "source": [
    "# Без пунктуации\n",
    "\n",
    "\n",
    "df = pd.DataFrame(Train_X)\n",
    "X_train_without_punct_df = df.drop(['punct_chars_cnt'], axis=1)\n",
    "\n",
    "df_test = pd.DataFrame(Test_X)\n",
    "X_test_without_punct_df = df_test.drop(['punct_chars_cnt'], axis=1)\n",
    "\n",
    "mapper = DataFrameMapper(\n",
    "    [\n",
    "        ('text', CountVectorizer()),\n",
    "        (['nouns_cnt', 'verbs_cnt', 'adjective_cnt', 'adverb_cnt'], None)\n",
    "    ])\n",
    "\n",
    "X = mapper.fit_transform(X_train_without_punct_df)\n",
    "X_test = mapper.transform(X_test_without_punct_df)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclf = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "rfclf.fit(X, Train_Y)\n",
    "\n",
    "predictions_RF = rfclf.predict(X_test)\n",
    "print(predictions_RF)\n",
    "print(\"RF Accuracy Score -> \",accuracy_score(predictions_RF, Test_Y)*100)\n",
    "print(precision_recall_fscore_support(Test_Y, predictions_RF, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
