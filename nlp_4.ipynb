{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with parsing\n"
     ]
    }
   ],
   "source": [
    "# coding: utf8\n",
    "import math\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "import pandas\n",
    "import pymorphy2\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "def normalize_review(review, morph):\n",
    "    \"\"\"\n",
    "\n",
    "    :param review:\n",
    "    :param morph:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = nltk.word_tokenize(review)\n",
    "    normalized_tokens = []\n",
    "    # normalized_review = ''\n",
    "    for token in tokens:\n",
    "        token = morph.parse(token)[0].normal_form\n",
    "        if token not in stop_words and token not in string.punctuation:\n",
    "            normalized_tokens.append(token.lower())\n",
    "\n",
    "    return normalized_tokens, \" \".join(normalized_tokens)\n",
    "\n",
    "\n",
    "def get_my_reviews(morph):\n",
    "    \"\"\"\n",
    "    Получаем мои ревью из эксель таблицы.\n",
    "\n",
    "    :param morph:\n",
    "    :return tuple: (название фильма, текст ревью, реальный класс ревью)\n",
    "    \"\"\"\n",
    "    pos_reviews = []\n",
    "    neg_reviews = []\n",
    "    neutr_reviews = []\n",
    "    \n",
    "    excel_file = pandas.read_excel('Отзывы кино.xlsx', 0)\n",
    "    for i, row in excel_file.iterrows():\n",
    "        if (row['title'] == 'Криминальное чтиво' or\n",
    "                row['title'] == 'Маленькая Мисс Счастье' or\n",
    "                row['title'] == 'Амели'):\n",
    "            \n",
    "            if row['label'] == 1:\n",
    "                pos_reviews.append((row['title'], normalize_review(row['text'], morph),\n",
    "                            str(row['label'])))\n",
    "            if row['label'] == -1:\n",
    "                neg_reviews.append((row['title'], normalize_review(row['text'], morph),\n",
    "                            str(row['label'])))\n",
    "            if row['label'] == 0:\n",
    "                neutr_reviews.append((row['title'], normalize_review(row['text'], morph),\n",
    "                            str(row['label'])))\n",
    "\n",
    "    return pos_reviews, neg_reviews, neutr_reviews\n",
    "\n",
    "\n",
    "def get_reviews(morph):\n",
    "    \"\"\"\n",
    "    Получаем ревью одногруппников из эксель таблицы.\n",
    "\n",
    "    :param morph:\n",
    "    :return tuple: (название фильма, список токенов, реальный класс ревью)\n",
    "    \"\"\"\n",
    "    pos_reviews = []\n",
    "    neg_reviews = []\n",
    "    neutr_reviews = []\n",
    "    \n",
    "    excel_file = pandas.read_excel('Отзывы кино.xlsx', 0)\n",
    "    for i, row in excel_file.iterrows():\n",
    "        if (row['title'] != 'Криминальное чтиво' and\n",
    "                row['title'] != 'Маленькая Мисс Счастье' and\n",
    "                row['title'] != 'Амели'):\n",
    "            if row['label'] == 1:\n",
    "                pos_reviews.append((row['title'], normalize_review(row['text'], morph),\n",
    "                            str(row['label'])))\n",
    "            if row['label'] == -1:\n",
    "                neg_reviews.append((row['title'], normalize_review(row['text'], morph),\n",
    "                            str(row['label'])))\n",
    "            if row['label'] == 0:\n",
    "                neutr_reviews.append((row['title'], normalize_review(row['text'], morph),\n",
    "                            str(row['label'])))\n",
    "            \n",
    "\n",
    "    return pos_reviews, neg_reviews, neutr_reviews\n",
    "\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "stop_words = stopwords.words('russian')\n",
    "stop_words.extend(['«', '»', '–', '...', '“', '”', '—', '!',\n",
    "                   '@', '№', ':', ',', '.', '?', ':', '(', ')'])\n",
    "stop_words = set(stop_words)\n",
    "\n",
    "train_pos_reviews, train_neg_reviews, train_neutr_reviews = get_reviews(morph)\n",
    "test_pos_reviews, test_neg_reviews, test_neutr_reviews = get_my_reviews(morph)\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.\n",
    "vectorizer = CountVectorizer(analyzer=\"word\")\n",
    "\n",
    "print('Done with parsing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_reviews = [item[1][1] for item in train_pos_reviews]\n",
    "train_neg_reviews = [item[1][1] for item in train_neg_reviews]\n",
    "train_neutr_reviews = [item[1][1] for item in train_neutr_reviews]\n",
    "\n",
    "test_pos_reviews = [item[1][1] for item in test_pos_reviews]\n",
    "test_neg_reviews = [item[1][1] for item in test_neg_reviews]\n",
    "test_neutr_reviews = [item[1][1] for item in test_neutr_reviews]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.60      0.60      0.60        30\n",
      "           0       0.35      0.20      0.26        30\n",
      "           1       0.51      0.73      0.60        30\n",
      "\n",
      "    accuracy                           0.51        90\n",
      "   macro avg       0.49      0.51      0.49        90\n",
      "weighted avg       0.49      0.51      0.49        90\n",
      "\n",
      "\n",
      "\n",
      "[[18  6  6]\n",
      " [ 9  6 15]\n",
      " [ 3  5 22]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "X = train_pos_reviews + train_neg_reviews + train_neutr_reviews\n",
    "y = [1]*len(train_pos_reviews) + [-1]*len(train_neg_reviews) + [0]*len(train_neutr_reviews)\n",
    "\n",
    "X_test = test_pos_reviews + test_neg_reviews + test_neutr_reviews\n",
    "y_test = [1]*len(test_pos_reviews) + [-1]*len(test_neg_reviews) + [0]*len(test_neutr_reviews)\n",
    "\n",
    "\n",
    "X = vectorizer.fit_transform(X).toarray()\n",
    "X_test = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "print('\\n')\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print('\\n')\n",
    "print(metrics.confusion_matrix(expected, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-0.4224993170831814, '118'), (-0.34832699146909, 'хитрость'), (-0.2080963483102299, 'клясться'), (-0.20236828004726676, 'отличие'), (-0.20161653838168586, 'островок'), (-0.19148154901150666, 'дикобраз'), (-0.1897950350566461, 'недоделать'), (-0.18553428673686054, 'же'), (-0.18247915943042012, 'зомби'), (-0.178737250576839, 'покровительствовать')]\n",
      "\n",
      "\n",
      "\n",
      "[(0.19146809260685735, 'место'), (0.1921136297530562, 'сравняться'), (0.19600552446892588, 'зацепить'), (0.19849772436260812, 'книга'), (0.19869962204899005, 'уголок'), (0.23752085260320338, 'контингент'), (0.250674542941112, 'смоделировать'), (0.26170925979211257, 'переработать'), (0.27682048890864147, 'предпринять'), (0.2798529812272922, 'добиться')]\n"
     ]
    }
   ],
   "source": [
    "weights = model.coef_[1]\n",
    "vectorizer = CountVectorizer(analyzer=\"word\")\n",
    "features = vectorizer.fit_transform(train_neutr_reviews).toarray()\n",
    "vocab = vectorizer.get_feature_names()\n",
    "mapping = zip(weights, vocab)\n",
    "\n",
    "mapping = sorted(mapping, key=lambda tup: tup[0])\n",
    "\n",
    "# первые 10\n",
    "print(mapping[:10])\n",
    "print('\\n\\n')\n",
    "# последние 10\n",
    "print(mapping[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-0.3749677564172916, 'утверждение'), (-0.27549871986642915, 'самый'), (-0.26698152287794186, 'отнимать'), (-0.25559594146182835, 'грязь'), (-0.24218162794789744, 'операторский'), (-0.23476466005635382, 'проехать'), (-0.21883591310344186, 'час'), (-0.21808043754516085, 'дожить'), (-0.2170701940962084, 'должность'), (-0.21426853857945297, 'пыльный')]\n",
      "\n",
      "\n",
      "\n",
      "[(0.2062403297996023, 'месиво'), (0.20741159128253583, 'неоправданность'), (0.22177988999851694, 'достать'), (0.2232030335949821, 'безработица'), (0.2245712604381366, 'упускать'), (0.22949627235922954, 'идентифицироваться'), (0.23499702690077592, 'порушить'), (0.2374573888335256, 'столкновение'), (0.25303334450916926, 'среднее'), (0.45079345334770116, 'стандарт')]\n"
     ]
    }
   ],
   "source": [
    "weights = model.coef_[0]\n",
    "vectorizer = CountVectorizer(analyzer=\"word\")\n",
    "features = vectorizer.fit_transform(train_neg_reviews).toarray()\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "mapping = zip(weights, vocab)\n",
    "\n",
    "mapping = sorted(mapping, key=lambda tup: tup[0])\n",
    "# первые 10\n",
    "print(mapping[:10])\n",
    "print('\\n\\n')\n",
    "# последние 10\n",
    "print(mapping[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-0.2697829046796834, 'кинопроектор'), (-0.21248175449060733, 'извращение'), (-0.21105825090106692, 'пересолить'), (-0.20967537709708334, 'смонтировать'), (-0.209253885085023, 'достать'), (-0.20594319839055508, 'пумбой'), (-0.20430878291690305, 'среднее'), (-0.1991172572862432, 'инстинкт'), (-0.19908487350225637, 'несущий'), (-0.17391922391537365, 'худоба')]\n",
      "\n",
      "\n",
      "\n",
      "[(0.21840259240459217, 'пощекотать'), (0.22075889001697743, 'неинтересно'), (0.22449748099714384, 'вредить'), (0.22737091341303603, 'срывать'), (0.2351558343409769, 'феллини'), (0.23539112226210188, 'суперидея'), (0.3403832002961056, 'хэнск'), (0.366021662868077, 'отнимать'), (0.3691119450139682, 'операторский'), (0.5264154902127656, '100')]\n"
     ]
    }
   ],
   "source": [
    "weights = model.coef_[2]\n",
    "vectorizer = CountVectorizer(analyzer=\"word\")\n",
    "features = vectorizer.fit_transform(train_neg_reviews).toarray()\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "mapping = zip(weights, vocab)\n",
    "\n",
    "mapping = sorted(mapping, key=lambda tup: tup[0])\n",
    "# первые 10\n",
    "print(mapping[:10])\n",
    "print('\\n\\n')\n",
    "# последние 10\n",
    "print(mapping[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
