{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "with open('ALL_reviews.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        texts.append(line)\n",
    "        \n",
    "with open('all_my_reviews.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        texts.append(line)       \n",
    "        \n",
    "        \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "max_words = 10000 # Max size of the dictionary\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "\n",
    "# Flatten the list of lists resulting from the tokenization. This will reduce the list\n",
    "# to one dimension, allowing us to apply the sliding window technique to predict the next word\n",
    "text = [item for sublist in sequences for item in sublist]\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45545"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_len = 15\n",
    "\n",
    "pred_len = 5\n",
    "\n",
    "train_len = sentence_len - pred_len\n",
    "\n",
    "seq = []\n",
    "\n",
    "# Sliding window to generate train data\n",
    "for i in range(len(text)-sentence_len):\n",
    "    seq.append(text[i:i+sentence_len])\n",
    "\n",
    "# Reverse dictionary to decode tokenized sequences back to words\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row in seq is a 15 word long window. We append he first 10 words as the input to predict the next word\n",
    "trainX = []\n",
    "trainy = []\n",
    "\n",
    "for i in seq:\n",
    "    trainX.append(i[:train_len])\n",
    "    trainy.append(i[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'реплики'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_map[1514]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(max_words, 50, input_length=train_len),\n",
    "    LSTM(100, return_sequences=True),\n",
    "    LSTM(100),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(max_words-1, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alyona\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "234366/234366 [==============================] - 142s 606us/step - loss: 7.3813 - accuracy: 0.0462\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.38128, saving model to ./model_weights.hdf5\n",
      "Epoch 2/300\n",
      "234366/234366 [==============================] - 125s 532us/step - loss: 7.2641 - accuracy: 0.0463\n",
      "\n",
      "Epoch 00002: loss improved from 7.38128 to 7.26406, saving model to ./model_weights.hdf5\n",
      "Epoch 3/300\n",
      "234366/234366 [==============================] - 124s 529us/step - loss: 7.2422 - accuracy: 0.0462\n",
      "\n",
      "Epoch 00003: loss improved from 7.26406 to 7.24222, saving model to ./model_weights.hdf5\n",
      "Epoch 4/300\n",
      "234366/234366 [==============================] - 124s 530us/step - loss: 7.2094 - accuracy: 0.0462\n",
      "\n",
      "Epoch 00004: loss improved from 7.24222 to 7.20942, saving model to ./model_weights.hdf5\n",
      "Epoch 5/300\n",
      "234366/234366 [==============================] - 124s 531us/step - loss: 7.1691 - accuracy: 0.0467\n",
      "\n",
      "Epoch 00005: loss improved from 7.20942 to 7.16908, saving model to ./model_weights.hdf5\n",
      "Epoch 6/300\n",
      "234366/234366 [==============================] - 125s 535us/step - loss: 7.1264 - accuracy: 0.0471\n",
      "\n",
      "Epoch 00006: loss improved from 7.16908 to 7.12642, saving model to ./model_weights.hdf5\n",
      "Epoch 7/300\n",
      "234366/234366 [==============================] - 127s 540us/step - loss: 7.0823 - accuracy: 0.0474\n",
      "\n",
      "Epoch 00007: loss improved from 7.12642 to 7.08233, saving model to ./model_weights.hdf5\n",
      "Epoch 8/300\n",
      "234366/234366 [==============================] - 124s 531us/step - loss: 7.0354 - accuracy: 0.0482\n",
      "\n",
      "Epoch 00008: loss improved from 7.08233 to 7.03542, saving model to ./model_weights.hdf5\n",
      "Epoch 9/300\n",
      "234366/234366 [==============================] - 125s 531us/step - loss: 6.9824 - accuracy: 0.0487\n",
      "\n",
      "Epoch 00009: loss improved from 7.03542 to 6.98244, saving model to ./model_weights.hdf5\n",
      "Epoch 10/300\n",
      "234366/234366 [==============================] - 125s 532us/step - loss: 6.9219 - accuracy: 0.0490 - loss: 6.9214 - accura - ETA: 0s - loss: 6.9\n",
      "\n",
      "Epoch 00010: loss improved from 6.98244 to 6.92189, saving model to ./model_weights.hdf5\n",
      "Epoch 11/300\n",
      "234366/234366 [==============================] - 125s 532us/step - loss: 6.8569 - accuracy: 0.0495\n",
      "\n",
      "Epoch 00011: loss improved from 6.92189 to 6.85692, saving model to ./model_weights.hdf5\n",
      "Epoch 12/300\n",
      "234366/234366 [==============================] - 125s 535us/step - loss: 6.7888 - accuracy: 0.0505\n",
      "\n",
      "Epoch 00012: loss improved from 6.85692 to 6.78883, saving model to ./model_weights.hdf5\n",
      "Epoch 13/300\n",
      "234366/234366 [==============================] - 125s 532us/step - loss: 6.7166 - accuracy: 0.0512\n",
      "\n",
      "Epoch 00013: loss improved from 6.78883 to 6.71660, saving model to ./model_weights.hdf5\n",
      "Epoch 14/300\n",
      "234366/234366 [==============================] - 124s 531us/step - loss: 6.6396 - accuracy: 0.0523\n",
      "\n",
      "Epoch 00014: loss improved from 6.71660 to 6.63960, saving model to ./model_weights.hdf5\n",
      "Epoch 15/300\n",
      "234366/234366 [==============================] - 124s 530us/step - loss: 6.5590 - accuracy: 0.0529\n",
      "\n",
      "Epoch 00015: loss improved from 6.63960 to 6.55902, saving model to ./model_weights.hdf5\n",
      "Epoch 16/300\n",
      "234366/234366 [==============================] - 124s 529us/step - loss: 6.4761 - accuracy: 0.0544\n",
      "\n",
      "Epoch 00016: loss improved from 6.55902 to 6.47613, saving model to ./model_weights.hdf5\n",
      "Epoch 17/300\n",
      "234366/234366 [==============================] - 124s 528us/step - loss: 6.3888 - accuracy: 0.0555\n",
      "\n",
      "Epoch 00017: loss improved from 6.47613 to 6.38878, saving model to ./model_weights.hdf5\n",
      "Epoch 18/300\n",
      "234366/234366 [==============================] - 119s 509us/step - loss: 6.2115 - accuracy: 0.0579\n",
      "\n",
      "Epoch 00019: loss improved from 6.30110 to 6.21150, saving model to ./model_weights.hdf5\n",
      "Epoch 20/300\n",
      "234366/234366 [==============================] - 126s 538us/step - loss: 6.1211 - accuracy: 0.0591\n",
      "\n",
      "Epoch 00020: loss improved from 6.21150 to 6.12107, saving model to ./model_weights.hdf5\n",
      "Epoch 21/300\n",
      "234366/234366 [==============================] - 126s 539us/step - loss: 6.0345 - accuracy: 0.0606\n",
      "\n",
      "Epoch 00021: loss improved from 6.12107 to 6.03446, saving model to ./model_weights.hdf5\n",
      "Epoch 22/300\n",
      "234366/234366 [==============================] - 128s 548us/step - loss: 5.9483 - accuracy: 0.0627\n",
      "\n",
      "Epoch 00022: loss improved from 6.03446 to 5.94831, saving model to ./model_weights.hdf5\n",
      "Epoch 23/300\n",
      "234366/234366 [==============================] - 145s 619us/step - loss: 5.8651 - accuracy: 0.0643\n",
      "\n",
      "Epoch 00023: loss improved from 5.94831 to 5.86511, saving model to ./model_weights.hdf5\n",
      "Epoch 24/300\n",
      "234366/234366 [==============================] - 171s 728us/step - loss: 5.7816 - accuracy: 0.0667\n",
      "\n",
      "Epoch 00024: loss improved from 5.86511 to 5.78163, saving model to ./model_weights.hdf5\n",
      "Epoch 25/300\n",
      "234366/234366 [==============================] - 164s 699us/step - loss: 5.7010 - accuracy: 0.0691\n",
      "\n",
      "Epoch 00025: loss improved from 5.78163 to 5.70095, saving model to ./model_weights.hdf5\n",
      "Epoch 26/300\n",
      "234366/234366 [==============================] - 176s 749us/step - loss: 5.6288 - accuracy: 0.0711 - loss: 5.6282  - ETA: 0s - loss: 5.6286 - accuracy\n",
      "\n",
      "Epoch 00026: loss improved from 5.70095 to 5.62876, saving model to ./model_weights.hdf5\n",
      "Epoch 27/300\n",
      "234366/234366 [==============================] - 175s 748us/step - loss: 5.5549 - accuracy: 0.0734\n",
      "\n",
      "Epoch 00027: loss improved from 5.62876 to 5.55488, saving model to ./model_weights.hdf5\n",
      "Epoch 28/300\n",
      "234366/234366 [==============================] - 169s 722us/step - loss: 5.4818 - accuracy: 0.0764\n",
      "\n",
      "Epoch 00028: loss improved from 5.55488 to 5.48180, saving model to ./model_weights.hdf5\n",
      "Epoch 29/300\n",
      "234366/234366 [==============================] - 173s 740us/step - loss: 5.4137 - accuracy: 0.0793\n",
      "\n",
      "Epoch 00029: loss improved from 5.48180 to 5.41371, saving model to ./model_weights.hdf5\n",
      "Epoch 30/300\n",
      "234366/234366 [==============================] - 183s 783us/step - loss: 5.3486 - accuracy: 0.0832\n",
      "\n",
      "Epoch 00030: loss improved from 5.41371 to 5.34859, saving model to ./model_weights.hdf5\n",
      "Epoch 31/300\n",
      "234366/234366 [==============================] - 169s 719us/step - loss: 5.2868 - accuracy: 0.0853\n",
      "\n",
      "Epoch 00031: loss improved from 5.34859 to 5.28679, saving model to ./model_weights.hdf5\n",
      "Epoch 32/300\n",
      "234366/234366 [==============================] - 171s 729us/step - loss: 5.2190 - accuracy: 0.0896\n",
      "\n",
      "Epoch 00032: loss improved from 5.28679 to 5.21899, saving model to ./model_weights.hdf5\n",
      "Epoch 33/300\n",
      "234366/234366 [==============================] - 168s 717us/step - loss: 5.1619 - accuracy: 0.0939\n",
      "\n",
      "Epoch 00033: loss improved from 5.21899 to 5.16194, saving model to ./model_weights.hdf5\n",
      "Epoch 34/300\n",
      "234366/234366 [==============================] - 171s 728us/step - loss: 5.1038 - accuracy: 0.0975\n",
      "\n",
      "Epoch 00034: loss improved from 5.16194 to 5.10383, saving model to ./model_weights.hdf5\n",
      "Epoch 35/300\n",
      "234366/234366 [==============================] - 179s 764us/step - loss: 5.0511 - accuracy: 0.1013\n",
      "\n",
      "Epoch 00035: loss improved from 5.10383 to 5.05111, saving model to ./model_weights.hdf5\n",
      "Epoch 36/300\n",
      "234366/234366 [==============================] - 172s 732us/step - loss: 4.9977 - accuracy: 0.1054\n",
      "\n",
      "Epoch 00036: loss improved from 5.05111 to 4.99774, saving model to ./model_weights.hdf5\n",
      "Epoch 37/300\n",
      "234366/234366 [==============================] - 170s 725us/step - loss: 4.9517 - accuracy: 0.1093\n",
      "\n",
      "Epoch 00037: loss improved from 4.99774 to 4.95167, saving model to ./model_weights.hdf5\n",
      "Epoch 38/300\n",
      "234366/234366 [==============================] - 172s 733us/step - loss: 4.8958 - accuracy: 0.1144\n",
      "\n",
      "Epoch 00038: loss improved from 4.95167 to 4.89585, saving model to ./model_weights.hdf5\n",
      "Epoch 39/300\n",
      "234366/234366 [==============================] - 171s 728us/step - loss: 4.8558 - accuracy: 0.1172\n",
      "\n",
      "Epoch 00039: loss improved from 4.89585 to 4.85576, saving model to ./model_weights.hdf5\n",
      "Epoch 40/300\n",
      "234366/234366 [==============================] - 168s 717us/step - loss: 4.8110 - accuracy: 0.1217\n",
      "\n",
      "Epoch 00040: loss improved from 4.85576 to 4.81098, saving model to ./model_weights.hdf5\n",
      "Epoch 41/300\n",
      "234366/234366 [==============================] - 176s 749us/step - loss: 4.7731 - accuracy: 0.1253\n",
      "\n",
      "Epoch 00041: loss improved from 4.81098 to 4.77305, saving model to ./model_weights.hdf5\n",
      "Epoch 42/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234366/234366 [==============================] - 179s 763us/step - loss: 4.7334 - accuracy: 0.1285\n",
      "\n",
      "Epoch 00042: loss improved from 4.77305 to 4.73338, saving model to ./model_weights.hdf5\n",
      "Epoch 43/300\n",
      "234366/234366 [==============================] - 215s 919us/step - loss: 4.6963 - accuracy: 0.1321\n",
      "\n",
      "Epoch 00043: loss improved from 4.73338 to 4.69625, saving model to ./model_weights.hdf5\n",
      "Epoch 44/300\n",
      "234366/234366 [==============================] - 168s 718us/step - loss: 4.6602 - accuracy: 0.1356\n",
      "\n",
      "Epoch 00044: loss improved from 4.69625 to 4.66019, saving model to ./model_weights.hdf5\n",
      "Epoch 45/300\n",
      "234366/234366 [==============================] - 145s 620us/step - loss: 4.6220 - accuracy: 0.1391\n",
      "\n",
      "Epoch 00045: loss improved from 4.66019 to 4.62197, saving model to ./model_weights.hdf5\n",
      "Epoch 46/300\n",
      "234366/234366 [==============================] - 145s 619us/step - loss: 4.5880 - accuracy: 0.1422\n",
      "\n",
      "Epoch 00046: loss improved from 4.62197 to 4.58803, saving model to ./model_weights.hdf5\n",
      "Epoch 47/300\n",
      "234366/234366 [==============================] - 146s 624us/step - loss: 4.5608 - accuracy: 0.1453\n",
      "\n",
      "Epoch 00047: loss improved from 4.58803 to 4.56078, saving model to ./model_weights.hdf5\n",
      "Epoch 48/300\n",
      "234366/234366 [==============================] - 158s 675us/step - loss: 4.5268 - accuracy: 0.1494\n",
      "\n",
      "Epoch 00048: loss improved from 4.56078 to 4.52682, saving model to ./model_weights.hdf5\n",
      "Epoch 49/300\n",
      "234366/234366 [==============================] - 161s 687us/step - loss: 4.4952 - accuracy: 0.1518\n",
      "\n",
      "Epoch 00049: loss improved from 4.52682 to 4.49517, saving model to ./model_weights.hdf5\n",
      "Epoch 50/300\n",
      "234366/234366 [==============================] - 180s 769us/step - loss: 4.4672 - accuracy: 0.1553\n",
      "\n",
      "Epoch 00050: loss improved from 4.49517 to 4.46724, saving model to ./model_weights.hdf5\n",
      "Epoch 51/300\n",
      "234366/234366 [==============================] - 153s 653us/step - loss: 4.4356 - accuracy: 0.1592\n",
      "\n",
      "Epoch 00051: loss improved from 4.46724 to 4.43561, saving model to ./model_weights.hdf5\n",
      "Epoch 52/300\n",
      "234366/234366 [==============================] - 157s 670us/step - loss: 4.4063 - accuracy: 0.1615\n",
      "\n",
      "Epoch 00052: loss improved from 4.43561 to 4.40626, saving model to ./model_weights.hdf5\n",
      "Epoch 53/300\n",
      "234366/234366 [==============================] - 149s 635us/step - loss: 4.3848 - accuracy: 0.1641\n",
      "\n",
      "Epoch 00053: loss improved from 4.40626 to 4.38481, saving model to ./model_weights.hdf5\n",
      "Epoch 54/300\n",
      "234366/234366 [==============================] - 145s 619us/step - loss: 4.3548 - accuracy: 0.1672\n",
      "\n",
      "Epoch 00054: loss improved from 4.38481 to 4.35482, saving model to ./model_weights.hdf5\n",
      "Epoch 55/300\n",
      "234366/234366 [==============================] - 128s 545us/step - loss: 4.3346 - accuracy: 0.1692\n",
      "\n",
      "Epoch 00055: loss improved from 4.35482 to 4.33457, saving model to ./model_weights.hdf5\n",
      "Epoch 56/300\n",
      "234366/234366 [==============================] - 126s 538us/step - loss: 4.3077 - accuracy: 0.1719\n",
      "\n",
      "Epoch 00056: loss improved from 4.33457 to 4.30767, saving model to ./model_weights.hdf5\n",
      "Epoch 57/300\n",
      "234366/234366 [==============================] - 135s 578us/step - loss: 4.2863 - accuracy: 0.1749\n",
      "\n",
      "Epoch 00057: loss improved from 4.30767 to 4.28627, saving model to ./model_weights.hdf5\n",
      "Epoch 58/300\n",
      "234366/234366 [==============================] - 144s 613us/step - loss: 4.2613 - accuracy: 0.1772\n",
      "\n",
      "Epoch 00058: loss improved from 4.28627 to 4.26128, saving model to ./model_weights.hdf5\n",
      "Epoch 59/300\n",
      "234366/234366 [==============================] - 129s 549us/step - loss: 4.2453 - accuracy: 0.1791\n",
      "\n",
      "Epoch 00059: loss improved from 4.26128 to 4.24531, saving model to ./model_weights.hdf5\n",
      "Epoch 60/300\n",
      "234366/234366 [==============================] - 126s 538us/step - loss: 4.2203 - accuracy: 0.1827\n",
      "\n",
      "Epoch 00060: loss improved from 4.24531 to 4.22027, saving model to ./model_weights.hdf5\n",
      "Epoch 61/300\n",
      "234366/234366 [==============================] - 124s 529us/step - loss: 4.1996 - accuracy: 0.1844\n",
      "\n",
      "Epoch 00061: loss improved from 4.22027 to 4.19958, saving model to ./model_weights.hdf5\n",
      "Epoch 62/300\n",
      "234366/234366 [==============================] - 136s 580us/step - loss: 4.1836 - accuracy: 0.1859\n",
      "\n",
      "Epoch 00062: loss improved from 4.19958 to 4.18363, saving model to ./model_weights.hdf5\n",
      "Epoch 63/300\n",
      "234366/234366 [==============================] - 150s 638us/step - loss: 4.1560 - accuracy: 0.1903\n",
      "\n",
      "Epoch 00063: loss improved from 4.18363 to 4.15597, saving model to ./model_weights.hdf5\n",
      "Epoch 64/300\n",
      "234366/234366 [==============================] - 139s 593us/step - loss: 4.1423 - accuracy: 0.1915\n",
      "\n",
      "Epoch 00064: loss improved from 4.15597 to 4.14231, saving model to ./model_weights.hdf5\n",
      "Epoch 65/300\n",
      "234366/234366 [==============================] - 128s 545us/step - loss: 4.1181 - accuracy: 0.1938\n",
      "\n",
      "Epoch 00065: loss improved from 4.14231 to 4.11809, saving model to ./model_weights.hdf5\n",
      "Epoch 66/300\n",
      "234366/234366 [==============================] - 128s 544us/step - loss: 4.0967 - accuracy: 0.1967\n",
      "\n",
      "Epoch 00066: loss improved from 4.11809 to 4.09671, saving model to ./model_weights.hdf5\n",
      "Epoch 67/300\n",
      "234366/234366 [==============================] - 130s 557us/step - loss: 4.0836 - accuracy: 0.1978\n",
      "\n",
      "Epoch 00067: loss improved from 4.09671 to 4.08356, saving model to ./model_weights.hdf5\n",
      "Epoch 68/300\n",
      "234366/234366 [==============================] - 131s 559us/step - loss: 4.0601 - accuracy: 0.2010\n",
      "\n",
      "Epoch 00068: loss improved from 4.08356 to 4.06013, saving model to ./model_weights.hdf5\n",
      "Epoch 69/300\n",
      "234366/234366 [==============================] - 131s 559us/step - loss: 4.0517 - accuracy: 0.2024\n",
      "\n",
      "Epoch 00069: loss improved from 4.06013 to 4.05166, saving model to ./model_weights.hdf5\n",
      "Epoch 70/300\n",
      "234366/234366 [==============================] - 131s 557us/step - loss: 4.0297 - accuracy: 0.2046\n",
      "\n",
      "Epoch 00070: loss improved from 4.05166 to 4.02968, saving model to ./model_weights.hdf5\n",
      "Epoch 71/300\n",
      "234366/234366 [==============================] - 131s 561us/step - loss: 4.0148 - accuracy: 0.2060\n",
      "\n",
      "Epoch 00071: loss improved from 4.02968 to 4.01480, saving model to ./model_weights.hdf5\n",
      "Epoch 72/300\n",
      "234366/234366 [==============================] - 131s 560us/step - loss: 4.0070 - accuracy: 0.2082\n",
      "\n",
      "Epoch 00072: loss improved from 4.01480 to 4.00705, saving model to ./model_weights.hdf5\n",
      "Epoch 73/300\n",
      "234366/234366 [==============================] - 138s 588us/step - loss: 3.9802 - accuracy: 0.2104\n",
      "\n",
      "Epoch 00073: loss improved from 4.00705 to 3.98023, saving model to ./model_weights.hdf5\n",
      "Epoch 74/300\n",
      "234366/234366 [==============================] - 132s 565us/step - loss: 3.9708 - accuracy: 0.2123\n",
      "\n",
      "Epoch 00074: loss improved from 3.98023 to 3.97077, saving model to ./model_weights.hdf5\n",
      "Epoch 75/300\n",
      "234366/234366 [==============================] - 127s 541us/step - loss: 3.9506 - accuracy: 0.2150\n",
      "\n",
      "Epoch 00075: loss improved from 3.97077 to 3.95065, saving model to ./model_weights.hdf5\n",
      "Epoch 76/300\n",
      "234366/234366 [==============================] - 133s 568us/step - loss: 3.9404 - accuracy: 0.2156\n",
      "\n",
      "Epoch 00076: loss improved from 3.95065 to 3.94040, saving model to ./model_weights.hdf5\n",
      "Epoch 77/300\n",
      "234366/234366 [==============================] - 131s 559us/step - loss: 3.9221 - accuracy: 0.2180\n",
      "\n",
      "Epoch 00077: loss improved from 3.94040 to 3.92212, saving model to ./model_weights.hdf5\n",
      "Epoch 78/300\n",
      "234366/234366 [==============================] - 124s 529us/step - loss: 3.9075 - accuracy: 0.2191\n",
      "\n",
      "Epoch 00078: loss improved from 3.92212 to 3.90754, saving model to ./model_weights.hdf5\n",
      "Epoch 79/300\n",
      "234366/234366 [==============================] - 136s 579us/step - loss: 3.8992 - accuracy: 0.2196\n",
      "\n",
      "Epoch 00079: loss improved from 3.90754 to 3.89921, saving model to ./model_weights.hdf5\n",
      "Epoch 80/300\n",
      "234366/234366 [==============================] - 136s 580us/step - loss: 3.8821 - accuracy: 0.2222\n",
      "\n",
      "Epoch 00080: loss improved from 3.89921 to 3.88212, saving model to ./model_weights.hdf5\n",
      "Epoch 81/300\n",
      "234366/234366 [==============================] - 135s 575us/step - loss: 3.8618 - accuracy: 0.2248\n",
      "\n",
      "Epoch 00081: loss improved from 3.88212 to 3.86183, saving model to ./model_weights.hdf5\n",
      "Epoch 82/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234366/234366 [==============================] - 133s 569us/step - loss: 3.8576 - accuracy: 0.2260\n",
      "\n",
      "Epoch 00082: loss improved from 3.86183 to 3.85764, saving model to ./model_weights.hdf5\n",
      "Epoch 83/300\n",
      "234366/234366 [==============================] - 137s 584us/step - loss: 3.8409 - accuracy: 0.2278\n",
      "\n",
      "Epoch 00083: loss improved from 3.85764 to 3.84094, saving model to ./model_weights.hdf5\n",
      "Epoch 84/300\n",
      "234366/234366 [==============================] - 128s 548us/step - loss: 3.8244 - accuracy: 0.2301\n",
      "\n",
      "Epoch 00084: loss improved from 3.84094 to 3.82435, saving model to ./model_weights.hdf5\n",
      "Epoch 85/300\n",
      "234366/234366 [==============================] - 136s 578us/step - loss: 3.8198 - accuracy: 0.2315\n",
      "\n",
      "Epoch 00085: loss improved from 3.82435 to 3.81984, saving model to ./model_weights.hdf5\n",
      "Epoch 86/300\n",
      "234366/234366 [==============================] - 135s 575us/step - loss: 3.8006 - accuracy: 0.2319\n",
      "\n",
      "Epoch 00086: loss improved from 3.81984 to 3.80057, saving model to ./model_weights.hdf5\n",
      "Epoch 87/300\n",
      "234366/234366 [==============================] - 142s 607us/step - loss: 3.7930 - accuracy: 0.2347\n",
      "\n",
      "Epoch 00087: loss improved from 3.80057 to 3.79298, saving model to ./model_weights.hdf5\n",
      "Epoch 88/300\n",
      "234366/234366 [==============================] - 130s 555us/step - loss: 3.7789 - accuracy: 0.2358\n",
      "\n",
      "Epoch 00088: loss improved from 3.79298 to 3.77889, saving model to ./model_weights.hdf5\n",
      "Epoch 89/300\n",
      "234366/234366 [==============================] - 132s 564us/step - loss: 3.7684 - accuracy: 0.2379\n",
      "\n",
      "Epoch 00089: loss improved from 3.77889 to 3.76842, saving model to ./model_weights.hdf5\n",
      "Epoch 90/300\n",
      "234366/234366 [==============================] - 131s 557us/step - loss: 3.7573 - accuracy: 0.2387\n",
      "\n",
      "Epoch 00090: loss improved from 3.76842 to 3.75725, saving model to ./model_weights.hdf5\n",
      "Epoch 91/300\n",
      "234366/234366 [==============================] - 127s 543us/step - loss: 3.7392 - accuracy: 0.2428\n",
      "\n",
      "Epoch 00091: loss improved from 3.75725 to 3.73921, saving model to ./model_weights.hdf5\n",
      "Epoch 92/300\n",
      "234366/234366 [==============================] - 128s 546us/step - loss: 3.7372 - accuracy: 0.2414\n",
      "\n",
      "Epoch 00092: loss improved from 3.73921 to 3.73724, saving model to ./model_weights.hdf5\n",
      "Epoch 93/300\n",
      "234366/234366 [==============================] - 129s 548us/step - loss: 3.7313 - accuracy: 0.2421\n",
      "\n",
      "Epoch 00093: loss improved from 3.73724 to 3.73128, saving model to ./model_weights.hdf5\n",
      "Epoch 94/300\n",
      "234366/234366 [==============================] - 128s 548us/step - loss: 3.7119 - accuracy: 0.2447\n",
      "\n",
      "Epoch 00094: loss improved from 3.73128 to 3.71185, saving model to ./model_weights.hdf5\n",
      "Epoch 95/300\n",
      "234366/234366 [==============================] - 128s 545us/step - loss: 3.6993 - accuracy: 0.2465\n",
      "\n",
      "Epoch 00095: loss improved from 3.71185 to 3.69932, saving model to ./model_weights.hdf5\n",
      "Epoch 96/300\n",
      "234366/234366 [==============================] - 128s 545us/step - loss: 3.6895 - accuracy: 0.2483\n",
      "\n",
      "Epoch 00096: loss improved from 3.69932 to 3.68953, saving model to ./model_weights.hdf5\n",
      "Epoch 97/300\n",
      "234366/234366 [==============================] - 127s 544us/step - loss: 3.6804 - accuracy: 0.2478\n",
      "\n",
      "Epoch 00097: loss improved from 3.68953 to 3.68042, saving model to ./model_weights.hdf5\n",
      "Epoch 98/300\n",
      "234366/234366 [==============================] - 127s 543us/step - loss: 3.6802 - accuracy: 0.2497\n",
      "\n",
      "Epoch 00098: loss improved from 3.68042 to 3.68018, saving model to ./model_weights.hdf5\n",
      "Epoch 99/300\n",
      "234366/234366 [==============================] - 128s 547us/step - loss: 3.6635 - accuracy: 0.2507\n",
      "\n",
      "Epoch 00099: loss improved from 3.68018 to 3.66350, saving model to ./model_weights.hdf5\n",
      "Epoch 100/300\n",
      "234366/234366 [==============================] - 129s 549us/step - loss: 3.6529 - accuracy: 0.2525\n",
      "\n",
      "Epoch 00100: loss improved from 3.66350 to 3.65288, saving model to ./model_weights.hdf5\n",
      "Epoch 101/300\n",
      "234366/234366 [==============================] - 128s 546us/step - loss: 3.6438 - accuracy: 0.2535\n",
      "\n",
      "Epoch 00101: loss improved from 3.65288 to 3.64379, saving model to ./model_weights.hdf5\n",
      "Epoch 102/300\n",
      "234366/234366 [==============================] - 127s 544us/step - loss: 3.6379 - accuracy: 0.2547\n",
      "\n",
      "Epoch 00102: loss improved from 3.64379 to 3.63788, saving model to ./model_weights.hdf5\n",
      "Epoch 103/300\n",
      "234366/234366 [==============================] - 128s 544us/step - loss: 3.6273 - accuracy: 0.2567\n",
      "\n",
      "Epoch 00103: loss improved from 3.63788 to 3.62728, saving model to ./model_weights.hdf5\n",
      "Epoch 104/300\n",
      "234366/234366 [==============================] - 127s 541us/step - loss: 3.6194 - accuracy: 0.2576\n",
      "\n",
      "Epoch 00104: loss improved from 3.62728 to 3.61944, saving model to ./model_weights.hdf5\n",
      "Epoch 105/300\n",
      "234366/234366 [==============================] - 129s 550us/step - loss: 3.5996 - accuracy: 0.2603\n",
      "\n",
      "Epoch 00105: loss improved from 3.61944 to 3.59963, saving model to ./model_weights.hdf5\n",
      "Epoch 106/300\n",
      "234366/234366 [==============================] - 130s 556us/step - loss: 3.6014 - accuracy: 0.2601\n",
      "\n",
      "Epoch 00106: loss did not improve from 3.59963\n",
      "Epoch 107/300\n",
      "234366/234366 [==============================] - 128s 547us/step - loss: 3.5919 - accuracy: 0.2608\n",
      "\n",
      "Epoch 00107: loss improved from 3.59963 to 3.59193, saving model to ./model_weights.hdf5\n",
      "Epoch 108/300\n",
      "234366/234366 [==============================] - 129s 549us/step - loss: 3.5846 - accuracy: 0.2621\n",
      "\n",
      "Epoch 00108: loss improved from 3.59193 to 3.58460, saving model to ./model_weights.hdf5\n",
      "Epoch 109/300\n",
      "234366/234366 [==============================] - 128s 548us/step - loss: 3.5672 - accuracy: 0.2643\n",
      "\n",
      "Epoch 00109: loss improved from 3.58460 to 3.56720, saving model to ./model_weights.hdf5\n",
      "Epoch 110/300\n",
      "234366/234366 [==============================] - 129s 550us/step - loss: 3.5693 - accuracy: 0.2633\n",
      "\n",
      "Epoch 00110: loss did not improve from 3.56720\n",
      "Epoch 111/300\n",
      "234366/234366 [==============================] - 128s 545us/step - loss: 3.5556 - accuracy: 0.2654\n",
      "\n",
      "Epoch 00111: loss improved from 3.56720 to 3.55562, saving model to ./model_weights.hdf5\n",
      "Epoch 112/300\n",
      "234366/234366 [==============================] - 128s 548us/step - loss: 3.5463 - accuracy: 0.2670\n",
      "\n",
      "Epoch 00112: loss improved from 3.55562 to 3.54631, saving model to ./model_weights.hdf5\n",
      "Epoch 113/300\n",
      "234366/234366 [==============================] - 129s 552us/step - loss: 3.5447 - accuracy: 0.2669\n",
      "\n",
      "Epoch 00113: loss improved from 3.54631 to 3.54469, saving model to ./model_weights.hdf5\n",
      "Epoch 114/300\n",
      "234366/234366 [==============================] - 128s 548us/step - loss: 3.5336 - accuracy: 0.2692\n",
      "\n",
      "Epoch 00114: loss improved from 3.54469 to 3.53361, saving model to ./model_weights.hdf5\n",
      "Epoch 115/300\n",
      "234366/234366 [==============================] - 126s 536us/step - loss: 3.5244 - accuracy: 0.2694\n",
      "\n",
      "Epoch 00115: loss improved from 3.53361 to 3.52436, saving model to ./model_weights.hdf5\n",
      "Epoch 116/300\n",
      "234366/234366 [==============================] - 134s 574us/step - loss: 3.5120 - accuracy: 0.2703\n",
      "\n",
      "Epoch 00116: loss improved from 3.52436 to 3.51201, saving model to ./model_weights.hdf5\n",
      "Epoch 117/300\n",
      "234366/234366 [==============================] - 135s 577us/step - loss: 3.5070 - accuracy: 0.2718\n",
      "\n",
      "Epoch 00117: loss improved from 3.51201 to 3.50700, saving model to ./model_weights.hdf5\n",
      "Epoch 118/300\n",
      "234366/234366 [==============================] - 135s 576us/step - loss: 3.5006 - accuracy: 0.2727\n",
      "\n",
      "Epoch 00118: loss improved from 3.50700 to 3.50062, saving model to ./model_weights.hdf5\n",
      "Epoch 119/300\n",
      "234366/234366 [==============================] - 135s 574us/step - loss: 3.4945 - accuracy: 0.2747\n",
      "\n",
      "Epoch 00119: loss improved from 3.50062 to 3.49449, saving model to ./model_weights.hdf5\n",
      "Epoch 120/300\n",
      "234366/234366 [==============================] - 135s 577us/step - loss: 3.4855 - accuracy: 0.2752\n",
      "\n",
      "Epoch 00120: loss improved from 3.49449 to 3.48553, saving model to ./model_weights.hdf5\n",
      "Epoch 121/300\n",
      "234366/234366 [==============================] - 137s 585us/step - loss: 3.4782 - accuracy: 0.2765\n",
      "\n",
      "Epoch 00121: loss improved from 3.48553 to 3.47823, saving model to ./model_weights.hdf5\n",
      "Epoch 122/300\n",
      "234366/234366 [==============================] - 136s 579us/step - loss: 3.4769 - accuracy: 0.2771\n",
      "\n",
      "Epoch 00122: loss improved from 3.47823 to 3.47690, saving model to ./model_weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/300\n",
      "234366/234366 [==============================] - 130s 556us/step - loss: 3.4568 - accuracy: 0.2783\n",
      "\n",
      "Epoch 00123: loss improved from 3.47690 to 3.45675, saving model to ./model_weights.hdf5\n",
      "Epoch 124/300\n",
      "234366/234366 [==============================] - 129s 552us/step - loss: 3.4590 - accuracy: 0.2797\n",
      "\n",
      "Epoch 00124: loss did not improve from 3.45675\n",
      "Epoch 125/300\n",
      "234366/234366 [==============================] - 133s 566us/step - loss: 3.4529 - accuracy: 0.2804\n",
      "\n",
      "Epoch 00125: loss improved from 3.45675 to 3.45295, saving model to ./model_weights.hdf5\n",
      "Epoch 126/300\n",
      "234366/234366 [==============================] - 132s 564us/step - loss: 3.4470 - accuracy: 0.2810\n",
      "\n",
      "Epoch 00126: loss improved from 3.45295 to 3.44695, saving model to ./model_weights.hdf5\n",
      "Epoch 127/300\n",
      "234366/234366 [==============================] - 133s 566us/step - loss: 3.4407 - accuracy: 0.2817\n",
      "\n",
      "Epoch 00127: loss improved from 3.44695 to 3.44067, saving model to ./model_weights.hdf5\n",
      "Epoch 128/300\n",
      "234366/234366 [==============================] - 127s 542us/step - loss: 3.4299 - accuracy: 0.2821\n",
      "\n",
      "Epoch 00128: loss improved from 3.44067 to 3.42989, saving model to ./model_weights.hdf5\n",
      "Epoch 129/300\n",
      "234366/234366 [==============================] - 123s 526us/step - loss: 3.4222 - accuracy: 0.2847\n",
      "\n",
      "Epoch 00129: loss improved from 3.42989 to 3.42216, saving model to ./model_weights.hdf5\n",
      "Epoch 130/300\n",
      "234366/234366 [==============================] - 127s 543us/step - loss: 3.4192 - accuracy: 0.2839\n",
      "\n",
      "Epoch 00130: loss improved from 3.42216 to 3.41920, saving model to ./model_weights.hdf5\n",
      "Epoch 131/300\n",
      "234366/234366 [==============================] - 128s 547us/step - loss: 3.4115 - accuracy: 0.2863\n",
      "\n",
      "Epoch 00131: loss improved from 3.41920 to 3.41148, saving model to ./model_weights.hdf5\n",
      "Epoch 132/300\n",
      "234366/234366 [==============================] - 135s 577us/step - loss: 3.4107 - accuracy: 0.2850\n",
      "\n",
      "Epoch 00132: loss improved from 3.41148 to 3.41071, saving model to ./model_weights.hdf5\n",
      "Epoch 133/300\n",
      "234366/234366 [==============================] - 162s 690us/step - loss: 3.3959 - accuracy: 0.2879\n",
      "\n",
      "Epoch 00133: loss improved from 3.41071 to 3.39594, saving model to ./model_weights.hdf5\n",
      "Epoch 134/300\n",
      "234366/234366 [==============================] - 130s 556us/step - loss: 3.3912 - accuracy: 0.2884\n",
      "\n",
      "Epoch 00134: loss improved from 3.39594 to 3.39121, saving model to ./model_weights.hdf5\n",
      "Epoch 135/300\n",
      "234366/234366 [==============================] - 127s 541us/step - loss: 3.3842 - accuracy: 0.2898\n",
      "\n",
      "Epoch 00135: loss improved from 3.39121 to 3.38418, saving model to ./model_weights.hdf5\n",
      "Epoch 136/300\n",
      "234366/234366 [==============================] - 127s 542us/step - loss: 3.3777 - accuracy: 0.2911\n",
      "\n",
      "Epoch 00136: loss improved from 3.38418 to 3.37768, saving model to ./model_weights.hdf5\n",
      "Epoch 137/300\n",
      "234366/234366 [==============================] - 128s 546us/step - loss: 3.3726 - accuracy: 0.2910\n",
      "\n",
      "Epoch 00137: loss improved from 3.37768 to 3.37261, saving model to ./model_weights.hdf5\n",
      "Epoch 138/300\n",
      "234366/234366 [==============================] - 135s 577us/step - loss: 3.3715 - accuracy: 0.2898\n",
      "\n",
      "Epoch 00138: loss improved from 3.37261 to 3.37147, saving model to ./model_weights.hdf5\n",
      "Epoch 139/300\n",
      "234366/234366 [==============================] - 143s 612us/step - loss: 3.3669 - accuracy: 0.2922\n",
      "\n",
      "Epoch 00139: loss improved from 3.37147 to 3.36689, saving model to ./model_weights.hdf5\n",
      "Epoch 140/300\n",
      "234366/234366 [==============================] - 132s 561us/step - loss: 3.3501 - accuracy: 0.2947\n",
      "\n",
      "Epoch 00140: loss improved from 3.36689 to 3.35013, saving model to ./model_weights.hdf5\n",
      "Epoch 141/300\n",
      "234366/234366 [==============================] - 138s 588us/step - loss: 3.3456 - accuracy: 0.2941\n",
      "\n",
      "Epoch 00141: loss improved from 3.35013 to 3.34563, saving model to ./model_weights.hdf5\n",
      "Epoch 142/300\n",
      "234366/234366 [==============================] - 134s 573us/step - loss: 3.3466 - accuracy: 0.2933\n",
      "\n",
      "Epoch 00142: loss did not improve from 3.34563\n",
      "Epoch 143/300\n",
      "234366/234366 [==============================] - 128s 545us/step - loss: 3.3431 - accuracy: 0.2956\n",
      "\n",
      "Epoch 00143: loss improved from 3.34563 to 3.34314, saving model to ./model_weights.hdf5\n",
      "Epoch 144/300\n",
      "234366/234366 [==============================] - 133s 566us/step - loss: 3.3351 - accuracy: 0.2968\n",
      "\n",
      "Epoch 00144: loss improved from 3.34314 to 3.33510, saving model to ./model_weights.hdf5\n",
      "Epoch 145/300\n",
      "234366/234366 [==============================] - 143s 611us/step - loss: 3.3265 - accuracy: 0.2972\n",
      "\n",
      "Epoch 00145: loss improved from 3.33510 to 3.32653, saving model to ./model_weights.hdf5\n",
      "Epoch 146/300\n",
      "234366/234366 [==============================] - 130s 553us/step - loss: 3.3209 - accuracy: 0.2990\n",
      "\n",
      "Epoch 00146: loss improved from 3.32653 to 3.32089, saving model to ./model_weights.hdf5\n",
      "Epoch 147/300\n",
      "234366/234366 [==============================] - 129s 552us/step - loss: 3.3252 - accuracy: 0.2977\n",
      "\n",
      "Epoch 00147: loss did not improve from 3.32089\n",
      "Epoch 148/300\n",
      "234366/234366 [==============================] - 129s 552us/step - loss: 3.3161 - accuracy: 0.2985\n",
      "\n",
      "Epoch 00148: loss improved from 3.32089 to 3.31606, saving model to ./model_weights.hdf5\n",
      "Epoch 149/300\n",
      "234366/234366 [==============================] - 144s 616us/step - loss: 3.3053 - accuracy: 0.3000\n",
      "\n",
      "Epoch 00149: loss improved from 3.31606 to 3.30526, saving model to ./model_weights.hdf5\n",
      "Epoch 150/300\n",
      "234366/234366 [==============================] - 175s 749us/step - loss: 3.3015 - accuracy: 0.3002\n",
      "\n",
      "Epoch 00150: loss improved from 3.30526 to 3.30154, saving model to ./model_weights.hdf5\n",
      "Epoch 151/300\n",
      "234366/234366 [==============================] - 174s 743us/step - loss: 3.2918 - accuracy: 0.3015\n",
      "\n",
      "Epoch 00151: loss improved from 3.30154 to 3.29185, saving model to ./model_weights.hdf5\n",
      "Epoch 152/300\n",
      "234366/234366 [==============================] - 174s 742us/step - loss: 3.2964 - accuracy: 0.3019\n",
      "\n",
      "Epoch 00152: loss did not improve from 3.29185\n",
      "Epoch 153/300\n",
      "234366/234366 [==============================] - 176s 751us/step - loss: 3.2826 - accuracy: 0.3043\n",
      "\n",
      "Epoch 00153: loss improved from 3.29185 to 3.28259, saving model to ./model_weights.hdf5\n",
      "Epoch 154/300\n",
      "234366/234366 [==============================] - 175s 747us/step - loss: 3.2870 - accuracy: 0.3026\n",
      "\n",
      "Epoch 00154: loss did not improve from 3.28259\n",
      "Epoch 155/300\n",
      "234366/234366 [==============================] - 175s 748us/step - loss: 3.2836 - accuracy: 0.3038\n",
      "\n",
      "Epoch 00155: loss did not improve from 3.28259\n",
      "Epoch 156/300\n",
      "234366/234366 [==============================] - 175s 747us/step - loss: 3.2729 - accuracy: 0.3056\n",
      "\n",
      "Epoch 00156: loss improved from 3.28259 to 3.27295, saving model to ./model_weights.hdf5\n",
      "Epoch 157/300\n",
      "234366/234366 [==============================] - 174s 744us/step - loss: 3.2635 - accuracy: 0.3058\n",
      "\n",
      "Epoch 00157: loss improved from 3.27295 to 3.26347, saving model to ./model_weights.hdf5\n",
      "Epoch 158/300\n",
      "234366/234366 [==============================] - 175s 745us/step - loss: 3.2672 - accuracy: 0.3058\n",
      "\n",
      "Epoch 00158: loss did not improve from 3.26347\n",
      "Epoch 159/300\n",
      "234366/234366 [==============================] - 175s 746us/step - loss: 3.2676 - accuracy: 0.3057\n",
      "\n",
      "Epoch 00159: loss did not improve from 3.26347\n",
      "Epoch 160/300\n",
      "234366/234366 [==============================] - 175s 746us/step - loss: 3.2552 - accuracy: 0.3067\n",
      "\n",
      "Epoch 00160: loss improved from 3.26347 to 3.25523, saving model to ./model_weights.hdf5\n",
      "Epoch 161/300\n",
      "234366/234366 [==============================] - 174s 743us/step - loss: 3.2533 - accuracy: 0.3082\n",
      "\n",
      "Epoch 00161: loss improved from 3.25523 to 3.25334, saving model to ./model_weights.hdf5\n",
      "Epoch 162/300\n",
      "234366/234366 [==============================] - 174s 744us/step - loss: 3.2494 - accuracy: 0.3090\n",
      "\n",
      "Epoch 00162: loss improved from 3.25334 to 3.24939, saving model to ./model_weights.hdf5\n",
      "Epoch 163/300\n",
      "234366/234366 [==============================] - 176s 749us/step - loss: 3.2405 - accuracy: 0.3102\n",
      "\n",
      "Epoch 00163: loss improved from 3.24939 to 3.24048, saving model to ./model_weights.hdf5\n",
      "Epoch 164/300\n",
      "234366/234366 [==============================] - 175s 748us/step - loss: 3.2348 - accuracy: 0.3114\n",
      "\n",
      "Epoch 00164: loss improved from 3.24048 to 3.23484, saving model to ./model_weights.hdf5\n",
      "Epoch 165/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234366/234366 [==============================] - 173s 737us/step - loss: 3.2318 - accuracy: 0.3110\n",
      "\n",
      "Epoch 00165: loss improved from 3.23484 to 3.23183, saving model to ./model_weights.hdf5\n",
      "Epoch 166/300\n",
      "234366/234366 [==============================] - 173s 738us/step - loss: 3.2197 - accuracy: 0.3127\n",
      "\n",
      "Epoch 00166: loss improved from 3.23183 to 3.21973, saving model to ./model_weights.hdf5\n",
      "Epoch 167/300\n",
      "234366/234366 [==============================] - 173s 737us/step - loss: 3.2276 - accuracy: 0.3109\n",
      "\n",
      "Epoch 00167: loss did not improve from 3.21973\n",
      "Epoch 168/300\n",
      "234366/234366 [==============================] - 173s 738us/step - loss: 3.2137 - accuracy: 0.3133\n",
      "\n",
      "Epoch 00168: loss improved from 3.21973 to 3.21373, saving model to ./model_weights.hdf5\n",
      "Epoch 169/300\n",
      "234366/234366 [==============================] - 174s 742us/step - loss: 3.2179 - accuracy: 0.3124\n",
      "\n",
      "Epoch 00169: loss did not improve from 3.21373\n",
      "Epoch 170/300\n",
      "234366/234366 [==============================] - 173s 737us/step - loss: 3.2093 - accuracy: 0.3139\n",
      "\n",
      "Epoch 00170: loss improved from 3.21373 to 3.20930, saving model to ./model_weights.hdf5\n",
      "Epoch 171/300\n",
      "234366/234366 [==============================] - 172s 732us/step - loss: 3.2063 - accuracy: 0.3144\n",
      "\n",
      "Epoch 00171: loss improved from 3.20930 to 3.20633, saving model to ./model_weights.hdf5\n",
      "Epoch 172/300\n",
      "234366/234366 [==============================] - 171s 730us/step - loss: 3.2033 - accuracy: 0.3151\n",
      "\n",
      "Epoch 00172: loss improved from 3.20633 to 3.20332, saving model to ./model_weights.hdf5\n",
      "Epoch 173/300\n",
      "234366/234366 [==============================] - 172s 734us/step - loss: 3.1993 - accuracy: 0.3155\n",
      "\n",
      "Epoch 00173: loss improved from 3.20332 to 3.19927, saving model to ./model_weights.hdf5\n",
      "Epoch 174/300\n",
      "234366/234366 [==============================] - 172s 734us/step - loss: 3.2092 - accuracy: 0.3146\n",
      "\n",
      "Epoch 00174: loss did not improve from 3.19927\n",
      "Epoch 175/300\n",
      "234366/234366 [==============================] - 191s 814us/step - loss: 3.1858 - accuracy: 0.3184\n",
      "\n",
      "Epoch 00175: loss improved from 3.19927 to 3.18578, saving model to ./model_weights.hdf5\n",
      "Epoch 176/300\n",
      "234366/234366 [==============================] - 154s 655us/step - loss: 3.1856 - accuracy: 0.3180\n",
      "\n",
      "Epoch 00176: loss improved from 3.18578 to 3.18555, saving model to ./model_weights.hdf5\n",
      "Epoch 177/300\n",
      "234366/234366 [==============================] - 147s 626us/step - loss: 3.1785 - accuracy: 0.3186\n",
      "\n",
      "Epoch 00177: loss improved from 3.18555 to 3.17846, saving model to ./model_weights.hdf5\n",
      "Epoch 178/300\n",
      "234366/234366 [==============================] - 131s 557us/step - loss: 3.1794 - accuracy: 0.3179\n",
      "\n",
      "Epoch 00178: loss did not improve from 3.17846\n",
      "Epoch 179/300\n",
      "234366/234366 [==============================] - 129s 549us/step - loss: 3.1791 - accuracy: 0.3183\n",
      "\n",
      "Epoch 00179: loss did not improve from 3.17846\n",
      "Epoch 180/300\n",
      "234366/234366 [==============================] - 127s 540us/step - loss: 3.1667 - accuracy: 0.3207\n",
      "\n",
      "Epoch 00180: loss improved from 3.17846 to 3.16668, saving model to ./model_weights.hdf5\n",
      "Epoch 181/300\n",
      "234366/234366 [==============================] - 127s 542us/step - loss: 3.1650 - accuracy: 0.3203\n",
      "\n",
      "Epoch 00181: loss improved from 3.16668 to 3.16502, saving model to ./model_weights.hdf5\n",
      "Epoch 182/300\n",
      "234366/234366 [==============================] - 130s 553us/step - loss: 3.1580 - accuracy: 0.3221\n",
      "\n",
      "Epoch 00182: loss improved from 3.16502 to 3.15800, saving model to ./model_weights.hdf5\n",
      "Epoch 183/300\n",
      "234366/234366 [==============================] - 129s 549us/step - loss: 3.1606 - accuracy: 0.3214\n",
      "\n",
      "Epoch 00183: loss did not improve from 3.15800\n",
      "Epoch 184/300\n",
      "234366/234366 [==============================] - 127s 543us/step - loss: 3.1507 - accuracy: 0.3232\n",
      "\n",
      "Epoch 00184: loss improved from 3.15800 to 3.15074, saving model to ./model_weights.hdf5\n",
      "Epoch 185/300\n",
      "234366/234366 [==============================] - 130s 555us/step - loss: 3.1582 - accuracy: 0.3223\n",
      "\n",
      "Epoch 00185: loss did not improve from 3.15074\n",
      "Epoch 186/300\n",
      "234366/234366 [==============================] - 133s 568us/step - loss: 3.1426 - accuracy: 0.3245\n",
      "\n",
      "Epoch 00186: loss improved from 3.15074 to 3.14255, saving model to ./model_weights.hdf5\n",
      "Epoch 187/300\n",
      "234366/234366 [==============================] - 124s 530us/step - loss: 3.1500 - accuracy: 0.3237\n",
      "\n",
      "Epoch 00187: loss did not improve from 3.14255\n",
      "Epoch 188/300\n",
      "234366/234366 [==============================] - 123s 526us/step - loss: 3.1443 - accuracy: 0.3235\n",
      "\n",
      "Epoch 00188: loss did not improve from 3.14255\n",
      "Epoch 189/300\n",
      "234366/234366 [==============================] - 128s 548us/step - loss: 3.1319 - accuracy: 0.3255\n",
      "\n",
      "Epoch 00189: loss improved from 3.14255 to 3.13187, saving model to ./model_weights.hdf5\n",
      "Epoch 190/300\n",
      "234366/234366 [==============================] - 130s 555us/step - loss: 3.1275 - accuracy: 0.3259\n",
      "\n",
      "Epoch 00190: loss improved from 3.13187 to 3.12747, saving model to ./model_weights.hdf5\n",
      "Epoch 191/300\n",
      "234366/234366 [==============================] - 130s 555us/step - loss: 3.1473 - accuracy: 0.3237\n",
      "\n",
      "Epoch 00191: loss did not improve from 3.12747\n",
      "Epoch 192/300\n",
      "234366/234366 [==============================] - 129s 553us/step - loss: 3.1213 - accuracy: 0.3274\n",
      "\n",
      "Epoch 00192: loss improved from 3.12747 to 3.12133, saving model to ./model_weights.hdf5\n",
      "Epoch 193/300\n",
      "234366/234366 [==============================] - 128s 545us/step - loss: 3.1199 - accuracy: 0.3266\n",
      "\n",
      "Epoch 00193: loss improved from 3.12133 to 3.11994, saving model to ./model_weights.hdf5\n",
      "Epoch 194/300\n",
      "234366/234366 [==============================] - 128s 545us/step - loss: 3.1187 - accuracy: 0.3275\n",
      "\n",
      "Epoch 00194: loss improved from 3.11994 to 3.11869, saving model to ./model_weights.hdf5\n",
      "Epoch 195/300\n",
      "234366/234366 [==============================] - 127s 542us/step - loss: 3.1162 - accuracy: 0.3274\n",
      "\n",
      "Epoch 00195: loss improved from 3.11869 to 3.11621, saving model to ./model_weights.hdf5\n",
      "Epoch 196/300\n",
      "234366/234366 [==============================] - 127s 543us/step - loss: 3.1145 - accuracy: 0.3290\n",
      "\n",
      "Epoch 00196: loss improved from 3.11621 to 3.11451, saving model to ./model_weights.hdf5\n",
      "Epoch 197/300\n",
      "234366/234366 [==============================] - 127s 543us/step - loss: 3.1049 - accuracy: 0.3289\n",
      "\n",
      "Epoch 00197: loss improved from 3.11451 to 3.10495, saving model to ./model_weights.hdf5\n",
      "Epoch 198/300\n",
      "234366/234366 [==============================] - 127s 544us/step - loss: 3.0985 - accuracy: 0.3306\n",
      "\n",
      "Epoch 00198: loss improved from 3.10495 to 3.09851, saving model to ./model_weights.hdf5\n",
      "Epoch 199/300\n",
      "234366/234366 [==============================] - 130s 555us/step - loss: 3.1038 - accuracy: 0.3295\n",
      "\n",
      "Epoch 00199: loss did not improve from 3.09851\n",
      "Epoch 200/300\n",
      "234366/234366 [==============================] - 127s 543us/step - loss: 3.0959 - accuracy: 0.3313\n",
      "\n",
      "Epoch 00200: loss improved from 3.09851 to 3.09595, saving model to ./model_weights.hdf5\n",
      "Epoch 201/300\n",
      "234366/234366 [==============================] - 127s 543us/step - loss: 3.0993 - accuracy: 0.3314\n",
      "\n",
      "Epoch 00201: loss did not improve from 3.09595\n",
      "Epoch 202/300\n",
      "234366/234366 [==============================] - 127s 543us/step - loss: 3.0933 - accuracy: 0.3319\n",
      "\n",
      "Epoch 00202: loss improved from 3.09595 to 3.09326, saving model to ./model_weights.hdf5\n",
      "Epoch 203/300\n",
      "234366/234366 [==============================] - 127s 542us/step - loss: 3.0971 - accuracy: 0.3309\n",
      "\n",
      "Epoch 00203: loss did not improve from 3.09326\n",
      "Epoch 204/300\n",
      "234366/234366 [==============================] - 127s 543us/step - loss: 3.0815 - accuracy: 0.3330\n",
      "\n",
      "Epoch 00204: loss improved from 3.09326 to 3.08153, saving model to ./model_weights.hdf5\n",
      "Epoch 205/300\n",
      "234366/234366 [==============================] - 128s 547us/step - loss: 3.0883 - accuracy: 0.3321\n",
      "\n",
      "Epoch 00205: loss did not improve from 3.08153\n",
      "Epoch 206/300\n",
      "234366/234366 [==============================] - 128s 545us/step - loss: 3.0778 - accuracy: 0.3333\n",
      "\n",
      "Epoch 00206: loss improved from 3.08153 to 3.07780, saving model to ./model_weights.hdf5\n",
      "Epoch 207/300\n",
      "234366/234366 [==============================] - 2778s 12ms/step - loss: 3.0802 - accuracy: 0.3340\n",
      "\n",
      "Epoch 00207: loss did not improve from 3.07780\n",
      "Epoch 208/300\n",
      "234366/234366 [==============================] - 138s 589us/step - loss: 3.0749 - accuracy: 0.3345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00208: loss improved from 3.07780 to 3.07494, saving model to ./model_weights.hdf5\n",
      "Epoch 209/300\n",
      "234366/234366 [==============================] - 137s 586us/step - loss: 3.0705 - accuracy: 0.3353\n",
      "\n",
      "Epoch 00209: loss improved from 3.07494 to 3.07050, saving model to ./model_weights.hdf5\n",
      "Epoch 210/300\n",
      "234366/234366 [==============================] - 127s 544us/step - loss: 3.0676 - accuracy: 0.3358\n",
      "\n",
      "Epoch 00210: loss improved from 3.07050 to 3.06756, saving model to ./model_weights.hdf5\n",
      "Epoch 211/300\n",
      "234366/234366 [==============================] - 127s 543us/step - loss: 3.0720 - accuracy: 0.3358\n",
      "\n",
      "Epoch 00211: loss did not improve from 3.06756\n",
      "Epoch 212/300\n",
      "234366/234366 [==============================] - 128s 548us/step - loss: 3.0574 - accuracy: 0.3371\n",
      "\n",
      "Epoch 00212: loss improved from 3.06756 to 3.05742, saving model to ./model_weights.hdf5\n",
      "Epoch 213/300\n",
      "234366/234366 [==============================] - 129s 549us/step - loss: 3.0586 - accuracy: 0.3362\n",
      "\n",
      "Epoch 00213: loss did not improve from 3.05742\n",
      "Epoch 214/300\n",
      "234366/234366 [==============================] - 129s 552us/step - loss: 3.0516 - accuracy: 0.3377\n",
      "\n",
      "Epoch 00214: loss improved from 3.05742 to 3.05159, saving model to ./model_weights.hdf5\n",
      "Epoch 215/300\n",
      "   256/234366 [..............................] - ETA: 3:07:02 - loss: 2.8895 - accuracy: 0.3711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alyona\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.132645). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234366/234366 [==============================] - 151s 645us/step - loss: 3.0542 - accuracy: 0.3371\n",
      "\n",
      "Epoch 00215: loss did not improve from 3.05159\n",
      "Epoch 216/300\n",
      "234366/234366 [==============================] - 148s 629us/step - loss: 3.0512 - accuracy: 0.3374\n",
      "\n",
      "Epoch 00216: loss improved from 3.05159 to 3.05124, saving model to ./model_weights.hdf5\n",
      "Epoch 217/300\n",
      "234366/234366 [==============================] - 128s 548us/step - loss: 3.0517 - accuracy: 0.3369\n",
      "\n",
      "Epoch 00217: loss did not improve from 3.05124\n",
      "Epoch 218/300\n",
      "234366/234366 [==============================] - 135s 576us/step - loss: 3.0435 - accuracy: 0.3395\n",
      "\n",
      "Epoch 00218: loss improved from 3.05124 to 3.04347, saving model to ./model_weights.hdf5\n",
      "Epoch 219/300\n",
      "234366/234366 [==============================] - 129s 550us/step - loss: 3.0424 - accuracy: 0.3392\n",
      "\n",
      "Epoch 00219: loss improved from 3.04347 to 3.04239, saving model to ./model_weights.hdf5\n",
      "Epoch 220/300\n",
      "234366/234366 [==============================] - 136s 580us/step - loss: 3.0339 - accuracy: 0.3396\n",
      "\n",
      "Epoch 00220: loss improved from 3.04239 to 3.03386, saving model to ./model_weights.hdf5\n",
      "Epoch 221/300\n",
      "234366/234366 [==============================] - 134s 572us/step - loss: 3.0340 - accuracy: 0.3401\n",
      "\n",
      "Epoch 00221: loss did not improve from 3.03386\n",
      "Epoch 222/300\n",
      "234366/234366 [==============================] - 137s 585us/step - loss: 3.0379 - accuracy: 0.3390\n",
      "\n",
      "Epoch 00222: loss did not improve from 3.03386\n",
      "Epoch 223/300\n",
      "234366/234366 [==============================] - 139s 591us/step - loss: 3.0352 - accuracy: 0.3391\n",
      "\n",
      "Epoch 00223: loss did not improve from 3.03386\n",
      "Epoch 224/300\n",
      "234366/234366 [==============================] - 126s 536us/step - loss: 3.0277 - accuracy: 0.3414\n",
      "\n",
      "Epoch 00224: loss improved from 3.03386 to 3.02766, saving model to ./model_weights.hdf5\n",
      "Epoch 225/300\n",
      "234366/234366 [==============================] - 130s 554us/step - loss: 3.0200 - accuracy: 0.3422\n",
      "\n",
      "Epoch 00225: loss improved from 3.02766 to 3.01999, saving model to ./model_weights.hdf5\n",
      "Epoch 226/300\n",
      "234366/234366 [==============================] - 129s 549us/step - loss: 3.0285 - accuracy: 0.3405\n",
      "\n",
      "Epoch 00226: loss did not improve from 3.01999\n",
      "Epoch 227/300\n",
      "234366/234366 [==============================] - 131s 558us/step - loss: 3.0229 - accuracy: 0.3419\n",
      "\n",
      "Epoch 00227: loss did not improve from 3.01999\n",
      "Epoch 228/300\n",
      "234366/234366 [==============================] - 129s 553us/step - loss: 3.0203 - accuracy: 0.3421\n",
      "\n",
      "Epoch 00228: loss did not improve from 3.01999\n",
      "Epoch 229/300\n",
      "234366/234366 [==============================] - 126s 537us/step - loss: 3.0150 - accuracy: 0.3440\n",
      "\n",
      "Epoch 00229: loss improved from 3.01999 to 3.01501, saving model to ./model_weights.hdf5\n",
      "Epoch 230/300\n",
      "234366/234366 [==============================] - 121s 516us/step - loss: 3.0051 - accuracy: 0.3436\n",
      "\n",
      "Epoch 00230: loss improved from 3.01501 to 3.00508, saving model to ./model_weights.hdf5\n",
      "Epoch 231/300\n",
      "234366/234366 [==============================] - 121s 516us/step - loss: 3.0088 - accuracy: 0.3441\n",
      "\n",
      "Epoch 00231: loss did not improve from 3.00508\n",
      "Epoch 232/300\n",
      "234366/234366 [==============================] - 120s 513us/step - loss: 3.0077 - accuracy: 0.3430\n",
      "\n",
      "Epoch 00232: loss did not improve from 3.00508\n",
      "Epoch 233/300\n",
      "234366/234366 [==============================] - 123s 526us/step - loss: 3.0084 - accuracy: 0.3445\n",
      "\n",
      "Epoch 00233: loss did not improve from 3.00508\n",
      "Epoch 234/300\n",
      "234366/234366 [==============================] - 128s 544us/step - loss: 2.9979 - accuracy: 0.3460\n",
      "\n",
      "Epoch 00234: loss improved from 3.00508 to 2.99787, saving model to ./model_weights.hdf5\n",
      "Epoch 235/300\n",
      "234366/234366 [==============================] - 122s 519us/step - loss: 2.9962 - accuracy: 0.3460\n",
      "\n",
      "Epoch 00235: loss improved from 2.99787 to 2.99622, saving model to ./model_weights.hdf5\n",
      "Epoch 236/300\n",
      "234366/234366 [==============================] - 124s 530us/step - loss: 2.9974 - accuracy: 0.3456\n",
      "\n",
      "Epoch 00236: loss did not improve from 2.99622\n",
      "Epoch 237/300\n",
      "234366/234366 [==============================] - 133s 569us/step - loss: 2.9904 - accuracy: 0.3476\n",
      "\n",
      "Epoch 00237: loss improved from 2.99622 to 2.99036, saving model to ./model_weights.hdf5\n",
      "Epoch 238/300\n",
      "234366/234366 [==============================] - 128s 548us/step - loss: 2.9896 - accuracy: 0.3474\n",
      "\n",
      "Epoch 00238: loss improved from 2.99036 to 2.98962, saving model to ./model_weights.hdf5\n",
      "Epoch 239/300\n",
      "234366/234366 [==============================] - 127s 543us/step - loss: 2.9976 - accuracy: 0.3463\n",
      "\n",
      "Epoch 00239: loss did not improve from 2.98962\n",
      "Epoch 240/300\n",
      "234366/234366 [==============================] - 131s 560us/step - loss: 2.9834 - accuracy: 0.3480\n",
      "\n",
      "Epoch 00240: loss improved from 2.98962 to 2.98344, saving model to ./model_weights.hdf5\n",
      "Epoch 241/300\n",
      "234366/234366 [==============================] - 131s 557us/step - loss: 2.9881 - accuracy: 0.3472\n",
      "\n",
      "Epoch 00241: loss did not improve from 2.98344\n",
      "Epoch 242/300\n",
      "234366/234366 [==============================] - 134s 573us/step - loss: 2.9837 - accuracy: 0.3479\n",
      "\n",
      "Epoch 00242: loss did not improve from 2.98344\n",
      "Epoch 243/300\n",
      "234366/234366 [==============================] - 137s 583us/step - loss: 2.9815 - accuracy: 0.3484\n",
      "\n",
      "Epoch 00243: loss improved from 2.98344 to 2.98154, saving model to ./model_weights.hdf5\n",
      "Epoch 244/300\n",
      "234366/234366 [==============================] - 127s 542us/step - loss: 2.9782 - accuracy: 0.3483\n",
      "\n",
      "Epoch 00244: loss improved from 2.98154 to 2.97820, saving model to ./model_weights.hdf5\n",
      "Epoch 245/300\n",
      "234366/234366 [==============================] - 128s 544us/step - loss: 2.9693 - accuracy: 0.3512\n",
      "\n",
      "Epoch 00245: loss improved from 2.97820 to 2.96932, saving model to ./model_weights.hdf5\n",
      "Epoch 246/300\n",
      "234366/234366 [==============================] - 129s 551us/step - loss: 2.9774 - accuracy: 0.3491\n",
      "\n",
      "Epoch 00246: loss did not improve from 2.96932\n",
      "Epoch 247/300\n",
      "234366/234366 [==============================] - 131s 558us/step - loss: 2.9701 - accuracy: 0.3507\n",
      "\n",
      "Epoch 00247: loss did not improve from 2.96932\n",
      "Epoch 248/300\n",
      "234366/234366 [==============================] - 130s 553us/step - loss: 2.9570 - accuracy: 0.3520\n",
      "\n",
      "Epoch 00248: loss improved from 2.96932 to 2.95695, saving model to ./model_weights.hdf5\n",
      "Epoch 249/300\n",
      "234366/234366 [==============================] - 128s 546us/step - loss: 2.9587 - accuracy: 0.3516\n",
      "\n",
      "Epoch 00249: loss did not improve from 2.95695\n",
      "Epoch 250/300\n",
      "234366/234366 [==============================] - 128s 546us/step - loss: 2.9560 - accuracy: 0.3513\n",
      "\n",
      "Epoch 00250: loss improved from 2.95695 to 2.95603, saving model to ./model_weights.hdf5\n",
      "Epoch 251/300\n",
      "234366/234366 [==============================] - 127s 543us/step - loss: 2.9627 - accuracy: 0.3509\n",
      "\n",
      "Epoch 00251: loss did not improve from 2.95603\n",
      "Epoch 252/300\n",
      "234366/234366 [==============================] - 128s 546us/step - loss: 2.9624 - accuracy: 0.3511\n",
      "\n",
      "Epoch 00252: loss did not improve from 2.95603\n",
      "Epoch 253/300\n",
      "234366/234366 [==============================] - 128s 545us/step - loss: 2.9561 - accuracy: 0.3508\n",
      "\n",
      "Epoch 00253: loss did not improve from 2.95603\n",
      "Epoch 254/300\n",
      "234366/234366 [==============================] - 129s 549us/step - loss: 2.9508 - accuracy: 0.3530\n",
      "\n",
      "Epoch 00254: loss improved from 2.95603 to 2.95077, saving model to ./model_weights.hdf5\n",
      "Epoch 255/300\n",
      "234366/234366 [==============================] - 127s 542us/step - loss: 2.9486 - accuracy: 0.3541\n",
      "\n",
      "Epoch 00255: loss improved from 2.95077 to 2.94859, saving model to ./model_weights.hdf5\n",
      "Epoch 256/300\n",
      "234366/234366 [==============================] - 128s 545us/step - loss: 2.9515 - accuracy: 0.3524\n",
      "\n",
      "Epoch 00256: loss did not improve from 2.94859\n",
      "Epoch 257/300\n",
      "234366/234366 [==============================] - 127s 544us/step - loss: 2.9396 - accuracy: 0.3546\n",
      "\n",
      "Epoch 00257: loss improved from 2.94859 to 2.93956, saving model to ./model_weights.hdf5\n",
      "Epoch 258/300\n",
      "234366/234366 [==============================] - 127s 543us/step - loss: 2.9392 - accuracy: 0.3540\n",
      "\n",
      "Epoch 00258: loss improved from 2.93956 to 2.93922, saving model to ./model_weights.hdf5\n",
      "Epoch 259/300\n",
      "234366/234366 [==============================] - 127s 544us/step - loss: 2.9396 - accuracy: 0.3554\n",
      "\n",
      "Epoch 00259: loss did not improve from 2.93922\n",
      "Epoch 260/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234366/234366 [==============================] - 126s 539us/step - loss: 2.9409 - accuracy: 0.3547\n",
      "\n",
      "Epoch 00260: loss did not improve from 2.93922\n",
      "Epoch 261/300\n",
      "234366/234366 [==============================] - 131s 558us/step - loss: 2.9317 - accuracy: 0.3555\n",
      "\n",
      "Epoch 00261: loss improved from 2.93922 to 2.93169, saving model to ./model_weights.hdf5\n",
      "Epoch 262/300\n",
      "234366/234366 [==============================] - 126s 539us/step - loss: 2.9256 - accuracy: 0.3564\n",
      "\n",
      "Epoch 00262: loss improved from 2.93169 to 2.92563, saving model to ./model_weights.hdf5\n",
      "Epoch 263/300\n",
      "234366/234366 [==============================] - 126s 537us/step - loss: 2.9252 - accuracy: 0.3568\n",
      "\n",
      "Epoch 00263: loss improved from 2.92563 to 2.92517, saving model to ./model_weights.hdf5\n",
      "Epoch 264/300\n",
      "234366/234366 [==============================] - 126s 539us/step - loss: 2.9362 - accuracy: 0.3557\n",
      "\n",
      "Epoch 00264: loss did not improve from 2.92517\n",
      "Epoch 265/300\n",
      "234366/234366 [==============================] - 128s 545us/step - loss: 2.9225 - accuracy: 0.3576\n",
      "\n",
      "Epoch 00265: loss improved from 2.92517 to 2.92246, saving model to ./model_weights.hdf5\n",
      "Epoch 266/300\n",
      "234366/234366 [==============================] - 128s 547us/step - loss: 2.9117 - accuracy: 0.3590\n",
      "\n",
      "Epoch 00266: loss improved from 2.92246 to 2.91167, saving model to ./model_weights.hdf5\n",
      "Epoch 267/300\n",
      "234366/234366 [==============================] - 127s 541us/step - loss: 2.9170 - accuracy: 0.3596\n",
      "\n",
      "Epoch 00267: loss did not improve from 2.91167\n",
      "Epoch 268/300\n",
      "234366/234366 [==============================] - 127s 544us/step - loss: 2.9271 - accuracy: 0.3559\n",
      "\n",
      "Epoch 00268: loss did not improve from 2.91167\n",
      "Epoch 269/300\n",
      "234366/234366 [==============================] - 126s 539us/step - loss: 2.9191 - accuracy: 0.3582\n",
      "\n",
      "Epoch 00269: loss did not improve from 2.91167\n",
      "Epoch 270/300\n",
      "234366/234366 [==============================] - 128s 548us/step - loss: 2.9098 - accuracy: 0.3589\n",
      "\n",
      "Epoch 00270: loss improved from 2.91167 to 2.90982, saving model to ./model_weights.hdf5\n",
      "Epoch 271/300\n",
      "234366/234366 [==============================] - 127s 541us/step - loss: 2.9080 - accuracy: 0.3595\n",
      "\n",
      "Epoch 00271: loss improved from 2.90982 to 2.90799, saving model to ./model_weights.hdf5\n",
      "Epoch 272/300\n",
      "234366/234366 [==============================] - 127s 541us/step - loss: 2.9038 - accuracy: 0.3598\n",
      "\n",
      "Epoch 00272: loss improved from 2.90799 to 2.90382, saving model to ./model_weights.hdf5\n",
      "Epoch 273/300\n",
      "234366/234366 [==============================] - 126s 540us/step - loss: 2.9117 - accuracy: 0.3584\n",
      "\n",
      "Epoch 00273: loss did not improve from 2.90382\n",
      "Epoch 274/300\n",
      "234366/234366 [==============================] - 127s 540us/step - loss: 2.9148 - accuracy: 0.3597\n",
      "\n",
      "Epoch 00274: loss did not improve from 2.90382\n",
      "Epoch 275/300\n",
      "234366/234366 [==============================] - 128s 544us/step - loss: 2.8967 - accuracy: 0.3613\n",
      "\n",
      "Epoch 00275: loss improved from 2.90382 to 2.89674, saving model to ./model_weights.hdf5\n",
      "Epoch 276/300\n",
      "234366/234366 [==============================] - 127s 544us/step - loss: 2.9018 - accuracy: 0.3601\n",
      "\n",
      "Epoch 00276: loss did not improve from 2.89674\n",
      "Epoch 277/300\n",
      "234366/234366 [==============================] - 127s 541us/step - loss: 2.8905 - accuracy: 0.3619\n",
      "\n",
      "Epoch 00277: loss improved from 2.89674 to 2.89054, saving model to ./model_weights.hdf5\n",
      "Epoch 278/300\n",
      "234366/234366 [==============================] - 130s 554us/step - loss: 2.9002 - accuracy: 0.3596\n",
      "\n",
      "Epoch 00278: loss did not improve from 2.89054\n",
      "Epoch 279/300\n",
      "234366/234366 [==============================] - 128s 546us/step - loss: 2.8812 - accuracy: 0.3639\n",
      "\n",
      "Epoch 00279: loss improved from 2.89054 to 2.88122, saving model to ./model_weights.hdf5\n",
      "Epoch 280/300\n",
      "234366/234366 [==============================] - 136s 582us/step - loss: 2.8998 - accuracy: 0.3614\n",
      "\n",
      "Epoch 00280: loss did not improve from 2.88122\n",
      "Epoch 281/300\n",
      "234366/234366 [==============================] - 141s 601us/step - loss: 2.8906 - accuracy: 0.3620\n",
      "\n",
      "Epoch 00281: loss did not improve from 2.88122\n",
      "Epoch 282/300\n",
      "234366/234366 [==============================] - 139s 594us/step - loss: 2.8798 - accuracy: 0.3639\n",
      "\n",
      "Epoch 00282: loss improved from 2.88122 to 2.87977, saving model to ./model_weights.hdf5\n",
      "Epoch 283/300\n",
      "234366/234366 [==============================] - 144s 616us/step - loss: 2.8835 - accuracy: 0.3648\n",
      "\n",
      "Epoch 00283: loss did not improve from 2.87977\n",
      "Epoch 284/300\n",
      "234366/234366 [==============================] - 138s 588us/step - loss: 2.8946 - accuracy: 0.3611\n",
      "\n",
      "Epoch 00284: loss did not improve from 2.87977\n",
      "Epoch 285/300\n",
      "234366/234366 [==============================] - 135s 574us/step - loss: 2.8774 - accuracy: 0.3650\n",
      "\n",
      "Epoch 00285: loss improved from 2.87977 to 2.87735, saving model to ./model_weights.hdf5\n",
      "Epoch 286/300\n",
      "234366/234366 [==============================] - 132s 565us/step - loss: 2.8779 - accuracy: 0.3644\n",
      "\n",
      "Epoch 00286: loss did not improve from 2.87735\n",
      "Epoch 287/300\n",
      "234366/234366 [==============================] - 130s 556us/step - loss: 2.8834 - accuracy: 0.3645\n",
      "\n",
      "Epoch 00287: loss did not improve from 2.87735\n",
      "Epoch 288/300\n",
      "234366/234366 [==============================] - 132s 564us/step - loss: 2.8742 - accuracy: 0.3654\n",
      "\n",
      "Epoch 00288: loss improved from 2.87735 to 2.87416, saving model to ./model_weights.hdf5\n",
      "Epoch 289/300\n",
      "234366/234366 [==============================] - 138s 588us/step - loss: 2.8699 - accuracy: 0.3664\n",
      "\n",
      "Epoch 00289: loss improved from 2.87416 to 2.86994, saving model to ./model_weights.hdf5\n",
      "Epoch 290/300\n",
      "234366/234366 [==============================] - 143s 611us/step - loss: 2.8742 - accuracy: 0.3654\n",
      "\n",
      "Epoch 00290: loss did not improve from 2.86994\n",
      "Epoch 291/300\n",
      "234366/234366 [==============================] - 146s 624us/step - loss: 2.8672 - accuracy: 0.3675\n",
      "\n",
      "Epoch 00291: loss improved from 2.86994 to 2.86718, saving model to ./model_weights.hdf5\n",
      "Epoch 292/300\n",
      "234366/234366 [==============================] - 141s 603us/step - loss: 2.8668 - accuracy: 0.3669\n",
      "\n",
      "Epoch 00292: loss improved from 2.86718 to 2.86676, saving model to ./model_weights.hdf5\n",
      "Epoch 293/300\n",
      "234366/234366 [==============================] - 142s 607us/step - loss: 2.8677 - accuracy: 0.3667\n",
      "\n",
      "Epoch 00293: loss did not improve from 2.86676\n",
      "Epoch 294/300\n",
      "234366/234366 [==============================] - 137s 585us/step - loss: 2.8569 - accuracy: 0.3673\n",
      "\n",
      "Epoch 00294: loss improved from 2.86676 to 2.85692, saving model to ./model_weights.hdf5\n",
      "Epoch 295/300\n",
      "234366/234366 [==============================] - 140s 599us/step - loss: 2.8600 - accuracy: 0.3675\n",
      "\n",
      "Epoch 00295: loss did not improve from 2.85692\n",
      "Epoch 296/300\n",
      "234366/234366 [==============================] - 141s 601us/step - loss: 2.8523 - accuracy: 0.3689\n",
      "\n",
      "Epoch 00296: loss improved from 2.85692 to 2.85230, saving model to ./model_weights.hdf5\n",
      "Epoch 297/300\n",
      "234366/234366 [==============================] - 140s 597us/step - loss: 2.8624 - accuracy: 0.3672\n",
      "\n",
      "Epoch 00297: loss did not improve from 2.85230\n",
      "Epoch 298/300\n",
      "234366/234366 [==============================] - 144s 616us/step - loss: 2.8572 - accuracy: 0.3681\n",
      "\n",
      "Epoch 00298: loss did not improve from 2.85230\n",
      "Epoch 299/300\n",
      "234366/234366 [==============================] - 139s 594us/step - loss: 2.8501 - accuracy: 0.3689\n",
      "\n",
      "Epoch 00299: loss improved from 2.85230 to 2.85007, saving model to ./model_weights.hdf5\n",
      "Epoch 300/300\n",
      "234366/234366 [==============================] - 138s 589us/step - loss: 2.8588 - accuracy: 0.3681\n",
      "\n",
      "Epoch 00300: loss did not improve from 2.85007\n"
     ]
    }
   ],
   "source": [
    "# Train model with checkpoints\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "filepath = \"./model_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "history = model.fit(numpy.asarray(trainX),\n",
    "         pd.get_dummies(numpy.asarray(trainy)),\n",
    "         epochs = 300,\n",
    "         batch_size = 128,\n",
    "         callbacks = callbacks_list,\n",
    "         verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def gen(model,seq,max_len = 15):\n",
    "    ''' Generates a sequence given a string seq using specified model until the total sequence length\n",
    "    reaches max_len'''\n",
    "    # Tokenize the input string\n",
    "    tokenized_sent = tokenizer.texts_to_sequences([seq])\n",
    "#     max_len = max_len+len(tokenized_sent[0])\n",
    "\n",
    "    # If sentence is not as long as the desired sentence length, we need to 'pad sequence' so that\n",
    "    # the array input shape is correct going into our LSTM. the `pad_sequences` function adds \n",
    "    # zeroes to the left side of our sequence until it becomes 19 long, the number of input features.\n",
    "    gen_res = seq.split(' ')\n",
    "    \n",
    "#     while len(tokenized_sent[0]) < max_len:\n",
    "#         padded_sentence = pad_sequences(tokenized_sent[-10:],maxlen=10)\n",
    "#         op = model.predict(np.asarray(padded_sentence).reshape(1,-1))\n",
    "#         tokenized_sent[0].append(op.argmax()+1)\n",
    "        \n",
    "    while len(gen_res) < max_len:\n",
    "        padded_sentence = pad_sequences(tokenized_sent[-10:],maxlen=10)\n",
    "        op = model.predict(np.asarray(padded_sentence).reshape(1,-1))\n",
    "        tokenized_sent[0].append(op.argmax()+1)\n",
    "        gen_res.append(reverse_word_map[op.argmax()+1])\n",
    "        \n",
    "#     return \" \".join(map(lambda x : reverse_word_map[x],tokenized_sent[0]))\n",
    "    return \" \".join(gen_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сценарий фильма явно состряпан на основе тех штампов, которые обеспечивают эдвард занимает роль первого оказался\n"
     ]
    }
   ],
   "source": [
    "print(gen(model, 'Сценарий фильма явно состряпан на основе тех штампов, которые обеспечивают'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_sentences = [\n",
    "    'Сценарий фильма явно состряпан на основе тех штампов, которые обеспечивают',\n",
    "    'Автору высшую степень рукопожатности и признательность тех, для кого снимали',\n",
    "    'Фильм - откровенный лубок со всеми штампами антисоветской и русофобской пропаганды',\n",
    "    'В общем, фильм ничего кроме омерзения не вызывает, настолько топорно воспроизводится',\n",
    "    'Прямо скажем, фильм по своему гениален. Потому что это ж',\n",
    "    'Начну несколько издали, потому что в упор писать о сериале',\n",
    "    'Сериал \"Зулейха открывает глаза\" это очередная попытка убедить зрителя, что',\n",
    "    'За исключением ряда преувеличений, анахронизмов и стереотипов, допустимых для художественного',\n",
    "    'Как итог, фильм получился легким, светлым, с хорошим чувством юмора',\n",
    "    'Серии несколько высосаны из пальца, при ламповой и уникальной атмосфере',\n",
    "    'У Смешариков есть все шансы снова стать чем-то культовым и',\n",
    "    'Без лишней скромности и без преувеличения стоит отметить что это',\n",
    "    'Здесь есть основной макросюжет и масса мелких микросюжетных зарисовок, которые',\n",
    "    'Можете смотреть этот мульт как развлечение, не вдаваясь в',\n",
    "    'Резюмируя, отметим, что сериал безукоризненно работает на всех уровнях – техническом,',\n",
    "    'Это увлекательное шоу с различными персонажами, научной тематикой и совершенствованием',\n",
    "    'Крайне качественно сделанный сериал с крепким сюжетом и качественным подбором',\n",
    "    'Множество сюжетных линий расчерчены как по линейке; и смотреть отдельно',\n",
    "    'Думаю это не столь значительно, ведь можно просто наслаждаться всплеском',\n",
    "    'Уверен, что мы с вами еще тысячу раз удивимся и'  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Сценарий фильма явно состряпан на основе тех штампов, которые обеспечивают эдвард занимает роль первого оказался\n",
      "2 Автору высшую степень рукопожатности и признательность тех, для кого снимали получились и каждый я фэнтези\n",
      "3 Фильм - откровенный лубок со всеми штампами антисоветской и русофобской пропаганды сцену вас говорить очень\n",
      "4 В общем, фильм ничего кроме омерзения не вызывает, настолько топорно воспроизводится посмотрела такие не улететь\n",
      "5 Прямо скажем, фильм по своему гениален. Потому что это ж отношении шедевр фильм культовый 1\n",
      "6 Начну несколько издали, потому что в упор писать о сериале категории скажу сказать не люблю\n",
      "7 Сериал \"Зулейха открывает глаза\" это очередная попытка убедить зрителя, что и которая но а где\n",
      "8 За исключением ряда преувеличений, анахронизмов и стереотипов, допустимых для художественного сцене человечество демонстрируя и особенности\n",
      "9 Как итог, фильм получился легким, светлым, с хорошим чувством юмора что никаких других равнодушным да\n",
      "10 Серии несколько высосаны из пальца, при ламповой и уникальной атмосфере новое быть что будет деле\n",
      "11 У Смешариков есть все шансы снова стать чем-то культовым и тот больного чего он могла\n",
      "12 Без лишней скромности и без преувеличения стоит отметить что это интереснее и равно и видим\n",
      "13 Здесь есть основной макросюжет и масса мелких микросюжетных зарисовок, которые жить какого но я очередной\n",
      "14 Можете смотреть этот мульт как развлечение, не вдаваясь в станет д потому я смотрел что\n",
      "15 Резюмируя, отметим, что сериал безукоризненно работает на всех уровнях – техническом, ни отсылок линии этом\n",
      "16 Это увлекательное шоу с различными персонажами, научной тематикой и совершенствованием запоминается малую ребенка и только\n",
      "17 Крайне качественно сделанный сериал с крепким сюжетом и качественным подбором д это менее форсажа него\n",
      "18 Множество сюжетных линий расчерчены как по линейке; и смотреть отдельно решает в в а и\n",
      "19 Думаю это не столь значительно, ведь можно просто наслаждаться всплеском целом что делает нечто похоже\n",
      "20 Уверен, что мы с вами еще тысячу раз удивимся и он увидеть и с его\n"
     ]
    }
   ],
   "source": [
    "for i, value in enumerate(my_test_sentences, 1):\n",
    "    print(i, gen(model, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
