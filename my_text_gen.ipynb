{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "with open('ALL_reviews.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        texts.append(line)\n",
    "        \n",
    "with open('all_my_reviews.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        texts.append(line)       \n",
    "        \n",
    "        \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "max_words = 10000 # Max size of the dictionary\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "\n",
    "# Flatten the list of lists resulting from the tokenization. This will reduce the list\n",
    "# to one dimension, allowing us to apply the sliding window technique to predict the next word\n",
    "text = [item for sublist in sequences for item in sublist]\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45545"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_len = 15\n",
    "\n",
    "pred_len = 5\n",
    "\n",
    "train_len = sentence_len - pred_len\n",
    "\n",
    "seq = []\n",
    "\n",
    "# Sliding window to generate train data\n",
    "for i in range(len(text)-sentence_len):\n",
    "    seq.append(text[i:i+sentence_len])\n",
    "\n",
    "# Reverse dictionary to decode tokenized sequences back to words\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row in seq is a 15 word long window. We append he first 10 words as the input to predict the next word\n",
    "trainX = []\n",
    "trainy = []\n",
    "\n",
    "for i in seq:\n",
    "    trainX.append(i[:train_len])\n",
    "    trainy.append(i[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'реплики'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_map[1514]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(max_words, 50, input_length=train_len),\n",
    "    LSTM(100, return_sequences=True),\n",
    "    LSTM(100),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(max_words-1, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "234366/234366 [==============================] - 129s 550us/step - loss: 7.2311 - accuracy: 0.0463\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.23112, saving model to ./model_weights.hdf5\n",
      "Epoch 2/50\n",
      "234366/234366 [==============================] - 124s 529us/step - loss: 7.1557 - accuracy: 0.0462\n",
      "\n",
      "Epoch 00002: loss improved from 7.23112 to 7.15572, saving model to ./model_weights.hdf5\n",
      "Epoch 3/50\n",
      "234366/234366 [==============================] - 123s 525us/step - loss: 7.1154 - accuracy: 0.0464\n",
      "\n",
      "Epoch 00003: loss improved from 7.15572 to 7.11541, saving model to ./model_weights.hdf5\n",
      "Epoch 4/50\n",
      "234366/234366 [==============================] - 124s 528us/step - loss: 7.0725 - accuracy: 0.0463\n",
      "\n",
      "Epoch 00004: loss improved from 7.11541 to 7.07245, saving model to ./model_weights.hdf5\n",
      "Epoch 5/50\n",
      "234366/234366 [==============================] - 124s 530us/step - loss: 7.0271 - accuracy: 0.0466\n",
      "\n",
      "Epoch 00005: loss improved from 7.07245 to 7.02707, saving model to ./model_weights.hdf5\n",
      "Epoch 6/50\n",
      "234366/234366 [==============================] - 124s 531us/step - loss: 6.9757 - accuracy: 0.0470\n",
      "\n",
      "Epoch 00006: loss improved from 7.02707 to 6.97573, saving model to ./model_weights.hdf5\n",
      "Epoch 7/50\n",
      "234366/234366 [==============================] - 124s 531us/step - loss: 6.9187 - accuracy: 0.0479\n",
      "\n",
      "Epoch 00007: loss improved from 6.97573 to 6.91865, saving model to ./model_weights.hdf5\n",
      "Epoch 8/50\n",
      "234366/234366 [==============================] - 125s 535us/step - loss: 6.8546 - accuracy: 0.0486\n",
      "\n",
      "Epoch 00008: loss improved from 6.91865 to 6.85462, saving model to ./model_weights.hdf5\n",
      "Epoch 9/50\n",
      "234366/234366 [==============================] - 125s 533us/step - loss: 6.7882 - accuracy: 0.0493\n",
      "\n",
      "Epoch 00009: loss improved from 6.85462 to 6.78816, saving model to ./model_weights.hdf5\n",
      "Epoch 10/50\n",
      "234366/234366 [==============================] - 124s 530us/step - loss: 6.7117 - accuracy: 0.0501\n",
      "\n",
      "Epoch 00010: loss improved from 6.78816 to 6.71167, saving model to ./model_weights.hdf5\n",
      "Epoch 11/50\n",
      "234366/234366 [==============================] - 124s 531us/step - loss: 6.6340 - accuracy: 0.0510\n",
      "\n",
      "Epoch 00011: loss improved from 6.71167 to 6.63404, saving model to ./model_weights.hdf5\n",
      "Epoch 12/50\n",
      "234366/234366 [==============================] - 125s 533us/step - loss: 6.5553 - accuracy: 0.0518\n",
      "\n",
      "Epoch 00012: loss improved from 6.63404 to 6.55534, saving model to ./model_weights.hdf5\n",
      "Epoch 13/50\n",
      "234366/234366 [==============================] - 126s 536us/step - loss: 6.4782 - accuracy: 0.0529\n",
      "\n",
      "Epoch 00013: loss improved from 6.55534 to 6.47820, saving model to ./model_weights.hdf5\n",
      "Epoch 14/50\n",
      "234366/234366 [==============================] - 125s 533us/step - loss: 6.3986 - accuracy: 0.0540\n",
      "\n",
      "Epoch 00014: loss improved from 6.47820 to 6.39863, saving model to ./model_weights.hdf5\n",
      "Epoch 15/50\n",
      "234366/234366 [==============================] - 124s 531us/step - loss: 6.3218 - accuracy: 0.0555\n",
      "\n",
      "Epoch 00015: loss improved from 6.39863 to 6.32181, saving model to ./model_weights.hdf5\n",
      "Epoch 16/50\n",
      "234366/234366 [==============================] - 123s 524us/step - loss: 6.2451 - accuracy: 0.0568\n",
      "\n",
      "Epoch 00016: loss improved from 6.32181 to 6.24510, saving model to ./model_weights.hdf5\n",
      "Epoch 17/50\n",
      "234366/234366 [==============================] - 123s 524us/step - loss: 6.1658 - accuracy: 0.0581\n",
      "\n",
      "Epoch 00017: loss improved from 6.24510 to 6.16582, saving model to ./model_weights.hdf5\n",
      "Epoch 18/50\n",
      "234366/234366 [==============================] - 123s 526us/step - loss: 6.0913 - accuracy: 0.0596\n",
      "\n",
      "Epoch 00018: loss improved from 6.16582 to 6.09132, saving model to ./model_weights.hdf5\n",
      "Epoch 19/50\n",
      "234366/234366 [==============================] - 124s 528us/step - loss: 6.0134 - accuracy: 0.0616\n",
      "\n",
      "Epoch 00019: loss improved from 6.09132 to 6.01342, saving model to ./model_weights.hdf5\n",
      "Epoch 20/50\n",
      "234366/234366 [==============================] - 123s 525us/step - loss: 5.9421 - accuracy: 0.0631\n",
      "\n",
      "Epoch 00020: loss improved from 6.01342 to 5.94210, saving model to ./model_weights.hdf5\n",
      "Epoch 21/50\n",
      "234366/234366 [==============================] - 124s 528us/step - loss: 5.8669 - accuracy: 0.0651\n",
      "\n",
      "Epoch 00021: loss improved from 5.94210 to 5.86691, saving model to ./model_weights.hdf5\n",
      "Epoch 22/50\n",
      "234366/234366 [==============================] - 124s 531us/step - loss: 5.7991 - accuracy: 0.0665\n",
      "\n",
      "Epoch 00022: loss improved from 5.86691 to 5.79913, saving model to ./model_weights.hdf5\n",
      "Epoch 23/50\n",
      "234366/234366 [==============================] - 125s 531us/step - loss: 5.7306 - accuracy: 0.0689\n",
      "\n",
      "Epoch 00023: loss improved from 5.79913 to 5.73055, saving model to ./model_weights.hdf5\n",
      "Epoch 24/50\n",
      "234366/234366 [==============================] - 123s 526us/step - loss: 5.6635 - accuracy: 0.0707\n",
      "\n",
      "Epoch 00024: loss improved from 5.73055 to 5.66345, saving model to ./model_weights.hdf5\n",
      "Epoch 25/50\n",
      "234366/234366 [==============================] - 124s 529us/step - loss: 5.5973 - accuracy: 0.0732\n",
      "\n",
      "Epoch 00025: loss improved from 5.66345 to 5.59735, saving model to ./model_weights.hdf5\n",
      "Epoch 26/50\n",
      "234366/234366 [==============================] - 124s 531us/step - loss: 5.5347 - accuracy: 0.0761\n",
      "\n",
      "Epoch 00026: loss improved from 5.59735 to 5.53471, saving model to ./model_weights.hdf5\n",
      "Epoch 27/50\n",
      "234366/234366 [==============================] - 125s 533us/step - loss: 5.4727 - accuracy: 0.0783\n",
      "\n",
      "Epoch 00027: loss improved from 5.53471 to 5.47273, saving model to ./model_weights.hdf5\n",
      "Epoch 28/50\n",
      "234366/234366 [==============================] - 125s 532us/step - loss: 5.4100 - accuracy: 0.0812\n",
      "\n",
      "Epoch 00028: loss improved from 5.47273 to 5.41001, saving model to ./model_weights.hdf5\n",
      "Epoch 29/50\n",
      "234366/234366 [==============================] - 123s 525us/step - loss: 5.3538 - accuracy: 0.0832\n",
      "\n",
      "Epoch 00029: loss improved from 5.41001 to 5.35384, saving model to ./model_weights.hdf5\n",
      "Epoch 30/50\n",
      "234366/234366 [==============================] - 123s 527us/step - loss: 5.3013 - accuracy: 0.0875\n",
      "\n",
      "Epoch 00030: loss improved from 5.35384 to 5.30128, saving model to ./model_weights.hdf5\n",
      "Epoch 31/50\n",
      "234366/234366 [==============================] - 123s 523us/step - loss: 5.2443 - accuracy: 0.0896\n",
      "\n",
      "Epoch 00031: loss improved from 5.30128 to 5.24431, saving model to ./model_weights.hdf5\n",
      "Epoch 32/50\n",
      "234366/234366 [==============================] - 123s 523us/step - loss: 5.1973 - accuracy: 0.0923\n",
      "\n",
      "Epoch 00032: loss improved from 5.24431 to 5.19728, saving model to ./model_weights.hdf5\n",
      "Epoch 33/50\n",
      "234366/234366 [==============================] - 124s 527us/step - loss: 5.1467 - accuracy: 0.0954\n",
      "\n",
      "Epoch 00033: loss improved from 5.19728 to 5.14670, saving model to ./model_weights.hdf5\n",
      "Epoch 34/50\n",
      "234366/234366 [==============================] - 124s 530us/step - loss: 5.0978 - accuracy: 0.0990\n",
      "\n",
      "Epoch 00034: loss improved from 5.14670 to 5.09782, saving model to ./model_weights.hdf5\n",
      "Epoch 35/50\n",
      "234366/234366 [==============================] - 125s 531us/step - loss: 5.0552 - accuracy: 0.1021\n",
      "\n",
      "Epoch 00035: loss improved from 5.09782 to 5.05517, saving model to ./model_weights.hdf5\n",
      "Epoch 36/50\n",
      "234366/234366 [==============================] - 124s 531us/step - loss: 5.0094 - accuracy: 0.1048\n",
      "\n",
      "Epoch 00036: loss improved from 5.05517 to 5.00942, saving model to ./model_weights.hdf5\n",
      "Epoch 37/50\n",
      "234366/234366 [==============================] - 126s 536us/step - loss: 4.9682 - accuracy: 0.1088\n",
      "\n",
      "Epoch 00037: loss improved from 5.00942 to 4.96815, saving model to ./model_weights.hdf5\n",
      "Epoch 38/50\n",
      "234366/234366 [==============================] - 137s 583us/step - loss: 4.9282 - accuracy: 0.1107\n",
      "\n",
      "Epoch 00038: loss improved from 4.96815 to 4.92823, saving model to ./model_weights.hdf5\n",
      "Epoch 39/50\n",
      "234366/234366 [==============================] - 128s 544us/step - loss: 4.8889 - accuracy: 0.1136\n",
      "\n",
      "Epoch 00039: loss improved from 4.92823 to 4.88889, saving model to ./model_weights.hdf5\n",
      "Epoch 40/50\n",
      "234366/234366 [==============================] - 129s 550us/step - loss: 4.8494 - accuracy: 0.1167\n",
      "\n",
      "Epoch 00040: loss improved from 4.88889 to 4.84938, saving model to ./model_weights.hdf5\n",
      "Epoch 41/50\n",
      "234366/234366 [==============================] - 126s 537us/step - loss: 4.8126 - accuracy: 0.1197\n",
      "\n",
      "Epoch 00041: loss improved from 4.84938 to 4.81258, saving model to ./model_weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "234366/234366 [==============================] - 126s 538us/step - loss: 4.7807 - accuracy: 0.1222\n",
      "\n",
      "Epoch 00042: loss improved from 4.81258 to 4.78065, saving model to ./model_weights.hdf5\n",
      "Epoch 43/50\n",
      "234366/234366 [==============================] - 126s 540us/step - loss: 4.7446 - accuracy: 0.1265\n",
      "\n",
      "Epoch 00043: loss improved from 4.78065 to 4.74456, saving model to ./model_weights.hdf5\n",
      "Epoch 44/50\n",
      "234366/234366 [==============================] - 130s 556us/step - loss: 4.7132 - accuracy: 0.1286\n",
      "\n",
      "Epoch 00044: loss improved from 4.74456 to 4.71319, saving model to ./model_weights.hdf5\n",
      "Epoch 45/50\n",
      "234366/234366 [==============================] - 123s 526us/step - loss: 4.6794 - accuracy: 0.1313\n",
      "\n",
      "Epoch 00045: loss improved from 4.71319 to 4.67939, saving model to ./model_weights.hdf5\n",
      "Epoch 46/50\n",
      "234366/234366 [==============================] - 124s 528us/step - loss: 4.6418 - accuracy: 0.1360\n",
      "\n",
      "Epoch 00046: loss improved from 4.67939 to 4.64176, saving model to ./model_weights.hdf5\n",
      "Epoch 47/50\n",
      "234366/234366 [==============================] - 125s 535us/step - loss: 4.6201 - accuracy: 0.1373\n",
      "\n",
      "Epoch 00047: loss improved from 4.64176 to 4.62014, saving model to ./model_weights.hdf5\n",
      "Epoch 48/50\n",
      "234366/234366 [==============================] - 124s 529us/step - loss: 4.5883 - accuracy: 0.1403\n",
      "\n",
      "Epoch 00048: loss improved from 4.62014 to 4.58827, saving model to ./model_weights.hdf5\n",
      "Epoch 49/50\n",
      "234366/234366 [==============================] - 126s 537us/step - loss: 4.5622 - accuracy: 0.1430\n",
      "\n",
      "Epoch 00049: loss improved from 4.58827 to 4.56216, saving model to ./model_weights.hdf5\n",
      "Epoch 50/50\n",
      "234366/234366 [==============================] - 125s 533us/step - loss: 4.5297 - accuracy: 0.1463\n",
      "\n",
      "Epoch 00050: loss improved from 4.56216 to 4.52970, saving model to ./model_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Train model with checkpoints\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "filepath = \"./model_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "history = model.fit(numpy.asarray(trainX),\n",
    "         pd.get_dummies(numpy.asarray(trainy)),\n",
    "         epochs = 50,\n",
    "         batch_size = 128,\n",
    "         callbacks = callbacks_list,\n",
    "         verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def gen(model,seq,max_len = 15):\n",
    "    ''' Generates a sequence given a string seq using specified model until the total sequence length\n",
    "    reaches max_len'''\n",
    "    # Tokenize the input string\n",
    "    tokenized_sent = tokenizer.texts_to_sequences([seq])\n",
    "#     max_len = max_len+len(tokenized_sent[0])\n",
    "\n",
    "    # If sentence is not as long as the desired sentence length, we need to 'pad sequence' so that\n",
    "    # the array input shape is correct going into our LSTM. the `pad_sequences` function adds \n",
    "    # zeroes to the left side of our sequence until it becomes 19 long, the number of input features.\n",
    "    gen_res = seq.split(' ')\n",
    "    \n",
    "#     while len(tokenized_sent[0]) < max_len:\n",
    "#         padded_sentence = pad_sequences(tokenized_sent[-10:],maxlen=10)\n",
    "#         op = model.predict(np.asarray(padded_sentence).reshape(1,-1))\n",
    "#         tokenized_sent[0].append(op.argmax()+1)\n",
    "        \n",
    "    while len(gen_res) < max_len:\n",
    "        padded_sentence = pad_sequences(tokenized_sent[-10:],maxlen=10)\n",
    "        op = model.predict(np.asarray(padded_sentence).reshape(1,-1))\n",
    "        tokenized_sent[0].append(op.argmax()+1)\n",
    "        gen_res.append(reverse_word_map[op.argmax()+1])\n",
    "        \n",
    "#     return \" \".join(map(lambda x : reverse_word_map[x],tokenized_sent[0]))\n",
    "    return \" \".join(gen_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сценарий фильма явно состряпан на основе тех штампов, которые обеспечивают пытаются его диалогов и премии\n"
     ]
    }
   ],
   "source": [
    "print(gen(model, 'Сценарий фильма явно состряпан на основе тех штампов, которые обеспечивают'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_sentences = [\n",
    "    'Сценарий фильма явно состряпан на основе тех штампов, которые обеспечивают',\n",
    "    'Автору высшую степень рукопожатности и признательность тех, для кого снимали',\n",
    "    'Фильм - откровенный лубок со всеми штампами антисоветской и русофобской пропаганды',\n",
    "    'В общем, фильм ничего кроме омерзения не вызывает, настолько топорно воспроизводится',\n",
    "    'Прямо скажем, фильм по своему гениален. Потому что это ж',\n",
    "    'Начну несколько издали, потому что в упор писать о сериале',\n",
    "    'Сериал \"Зулейха открывает глаза\" это очередная попытка убедить зрителя, что',\n",
    "    'За исключением ряда преувеличений, анахронизмов и стереотипов, допустимых для художественного',\n",
    "    'Как итог, фильм получился легким, светлым, с хорошим чувством юмора',\n",
    "    'Серии несколько высосаны из пальца, при ламповой и уникальной атмосфере',\n",
    "    'У Смешариков есть все шансы снова стать чем-то культовым и',\n",
    "    'Без лишней скромности и без преувеличения стоит отметить что это',\n",
    "    'Здесь есть основной макросюжет и масса мелких микросюжетных зарисовок, которые',\n",
    "    'Можете смотреть этот мульт как развлечение, не вдаваясь в',\n",
    "    'Резюмируя, отметим, что сериал безукоризненно работает на всех уровнях – техническом,',\n",
    "    'Это увлекательное шоу с различными персонажами, научной тематикой и совершенствованием',\n",
    "    'Крайне качественно сделанный сериал с крепким сюжетом и качественным подбором',\n",
    "    'Множество сюжетных линий расчерчены как по линейке; и смотреть отдельно',\n",
    "    'Думаю это не столь значительно, ведь можно просто наслаждаться всплеском',\n",
    "    'Уверен, что мы с вами еще тысячу раз удивимся и'  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Сценарий фильма явно состряпан на основе тех штампов, которые обеспечивают пытаются его диалогов и премии\n",
      "2 Автору высшую степень рукопожатности и признательность тех, для кого снимали то 10 сказать хотелось простительно\n",
      "3 Фильм - откровенный лубок со всеми штампами антисоветской и русофобской пропаганды сценаристы а и бесконечное\n",
      "4 В общем, фильм ничего кроме омерзения не вызывает, настолько топорно воспроизводится что не и и\n",
      "5 Прямо скажем, фильм по своему гениален. Потому что это ж и наблюдали конечно и образом\n",
      "6 Начну несколько издали, потому что в упор писать о сериале связано несколько да так что\n",
      "7 Сериал \"Зулейха открывает глаза\" это очередная попытка убедить зрителя, что и за — что в\n",
      "8 За исключением ряда преувеличений, анахронизмов и стереотипов, допустимых для художественного единственные и в фильме и\n",
      "9 Как итог, фильм получился легким, светлым, с хорошим чувством юмора не считаю человек будут концепций\n",
      "10 Серии несколько высосаны из пальца, при ламповой и уникальной атмосфере и всем но том того\n",
      "11 У Смешариков есть все шансы снова стать чем-то культовым и детская персонажам подачей передал поля\n",
      "12 Без лишней скромности и без преувеличения стоит отметить что это и и и и и\n",
      "13 Здесь есть основной макросюжет и масса мелких микросюжетных зарисовок, которые то равно фильм шёл и\n",
      "14 Можете смотреть этот мульт как развлечение, не вдаваясь в не встает торин помощник в ней\n",
      "15 Резюмируя, отметим, что сериал безукоризненно работает на всех уровнях – техническом, один получали героя что\n",
      "16 Это увлекательное шоу с различными персонажами, научной тематикой и совершенствованием и попытку фильма все понравиться\n",
      "17 Крайне качественно сделанный сериал с крепким сюжетом и качественным подбором молодежи человека но может казалось\n",
      "18 Множество сюжетных линий расчерчены как по линейке; и смотреть отдельно приём и и сожалению прошло\n",
      "19 Думаю это не столь значительно, ведь можно просто наслаждаться всплеском и и и поговорим и\n",
      "20 Уверен, что мы с вами еще тысячу раз удивимся и быть в менее воображении популярная\n"
     ]
    }
   ],
   "source": [
    "for i, value in enumerate(my_test_sentences, 1):\n",
    "    print(i, gen(model, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
